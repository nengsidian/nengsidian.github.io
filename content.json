{"meta":{"title":"李恒的博客","subtitle":"记录知识，带来成长","description":"记录python、java等语言的编程知识","author":"liheng","url":"http://yoursite.com"},"pages":[{"title":"categories","date":"2020-05-16T01:00:17.000Z","updated":"2020-05-16T01:01:07.198Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-05-16T01:02:23.000Z","updated":"2020-05-16T01:02:46.515Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"mongodb常规操作","slug":"databases/mongodb常规操作","date":"2020-05-16T01:05:57.000Z","updated":"2020-05-16T02:14:55.041Z","comments":true,"path":"2020/05/16/databases/mongodb常规操作/","link":"","permalink":"http://yoursite.com/2020/05/16/databases/mongodb%E5%B8%B8%E8%A7%84%E6%93%8D%E4%BD%9C/","excerpt":"","text":"###一、数据库和集合的相关操作 1234567891011121314151617181920212223# 查看当前数据库db # 查看所有的数据库show dbs show databases # 查看集合show collections# 切换数据库use 数据库名字 # 删除当前数据库db.dropDatabase() # 删除集合db.集合名称.drop() # 手动创建集合 # db.createCollection(name,options) db.createCollection(\"stu\") db.createCollection(\"sub,&#123;capped:true,size:10&#125;) 参数capped： 默认值为false表示不设置上限,值为true表示设置上限 参数size： 当capped值为true时， 需要指定此参数， 表示上限⼤⼩,当⽂档达到上限时， 会将之前的数据覆盖， 单位为字节 注意：数据库和集合都不需要手动创建，添加数据时都会被自动创建出来，但是集合也可以手动创建 ###二、数据库的增删改查 集合名称：stu ####插入insert 123456789101112131415# 插入db.stu.insert(&#123;name:'gt',gender:1&#125;)db.stu.insert(&#123;_id:\"20170101\",name:'gj',gender:1&#125;)# 批量插入db.t254.insertMany( [ &#123; \"country\" : \"china\", \"province\" : \"sh\", \"userid\" : \"a\" &#125;, &#123; \"country\" : \"china\", \"province\" : \"sh\", \"userid\" : \"b\" &#125;, &#123; \"country\" : \"china\", \"province\" : \"sh\", \"userid\" : \"a\" &#125;, &#123; \"country\" : \"china\", \"province\" : \"sh\", \"userid\" : \"c\" &#125;, &#123; \"country\" : \"china\", \"province\" : \"bj\", \"userid\" : \"da\" &#125;, &#123; \"country\" : \"china\", \"province\" : \"bj\", \"userid\" : \"fa\" &#125; ]) •插⼊⽂档时， 如果不指定_id参数，MongoDB会为⽂档分配⼀个唯⼀的ObjectId 用insert插入时，如果id已存在则会报错 ####保存save 123# 保存db.stu.save(&#123;name:'gt',gender:2&#125;) # 新增db.stu.save(&#123;_id:\"20170101\",name:'gj',gender:1&#125;) # id已存在，则更新 如果⽂档的_id已经存在则修改，如果⽂档的_id不存在则添加 注意： db.collecion.insert({}) 插入数据，_id存在就报错 db.collection.save({}) 插入数据，_id存在会更新 更新update123456789# 更新db.集合名称.update(&lt;query&gt; ,&lt;update&gt;,&#123;multi:&lt;boolean&gt;&#125;)# 参数query:查询条件# 参数update:更新操作符# 参数multi:可选， 默认是false，表示只更新找到的第⼀条记录， 值为true表示把满⾜条件的⽂档全部更新db.stu.update(&#123;name:'hr'&#125;,&#123;name:'mnc'&#125;) # 更新一条，替换覆盖db.stu.update(&#123;name:'hr'&#125;,&#123;$set:&#123;name:'hys'&#125;&#125;) # 更新一条db.stu.update(&#123;&#125;,&#123;$set:&#123;gender:0&#125;&#125;,&#123;multi:true&#125;) # 更新全部 注意：”multi update only works with $ operators” 删除remove1234db.集合名称.remove(&lt;query&gt;,&#123;justOne: &lt;boolean&gt;&#125;)# 参数query:可选，删除的⽂档的条件# 参数justOne:可选， 如果设为true或1， 则只删除⼀条， 默认false， 表示删除多条 查询find普通查询： 12345678# 查询db.stu.find(&#123;条件文档&#125;)# 查询，只返回一个结果db.stu.findOne(&#123;条件文档&#125;)# 将查询结果格式化(方便查看)db.stu.find(&#123;条件文档&#125; 比较运算符： 1234567891011121314# 小于 $lt [less than]db.stu.find(&#123;age:&#123;$lt:18&#125;&#125;)# 小于等于 $lte [less than equal]db.stu.find(&#123;age:&#123;$lte:18&#125;&#125;)# 大于 $gt [greater than]db.stu.find(&#123;age:&#123;$gt:18&#125;&#125;)# 大于等于 $gte [greater than equal]db.stu.find(&#123;age:&#123;$gte:18&#125;&#125;)# 不等于 $nedb.stu.find(&#123;age:&#123;$ne:18&#125;&#125;) 逻辑运算符 12345678910# and 在json中写多个条件即可# 查询年龄大于等于18，并且性别为true的学生db.stu.find(&#123;age:&#123;$gte:18&#125;,gender:true&#125;)# or:使⽤$or， 值为数组 数组中每个元素为json# 查询年龄⼤于18， 或性别为false的学⽣db.stu.find(&#123;$or:[&#123;age:&#123;$gt:18&#125;&#125;,&#123;gender:false&#125;]&#125;)# 查询年龄⼤于18或性别为男⽣， 并且姓名是郭靖db.stu.find(&#123;$or:[&#123;age:&#123;$gt:18&#125;&#125;,&#123;gender:true&#125;],name:\"郭靖\"&#125;) 范围运算符123456# 使⽤\"$in\"， \"$nin\" 判断是否在某个范围内# 查询年龄为18、 28的学⽣# $in 在范围内db.stu.find(&#123;age:&#123;$in:[18,28]&#125;&#125;)# $nin 不在范围内db.collection.find(&#123;name:&#123;$nin:[\"a\",\"b\",\"c\"]&#125;&#125;) 正则表达式1234# 使⽤//或$regex编写正则表达式# 查询姓⻩的学⽣db.stu.find(&#123;name:/^⻩/&#125;)db.stu.find(&#123;name:&#123;$regex:'^⻩'&#125;&#125;) limit和skip limit(): ⽤于读取指定数量的⽂档 skip(): ⽤于跳过指定数量的⽂档 1234567891011# db.集合名称.find().limit(NUMBER)# 查询2条学⽣信息db.stu.find().limit(2)# db.集合名称.find().skip(NUMBER)db.stu.find().skip(2)# 同时使用db.stu.find().limit(4).skip(5)# 或 db.stu.find().skip(5).limit(4) 自定义查询12345# 使⽤$where后⾯写⼀个函数， 返回满⾜条件的数据，查询年龄⼤于30的学⽣db.stu.find(&#123; $where:function() &#123; return this.age&gt;30;&#125;&#125;) 投影在查询到的返回结果中， 只选择必要的字段 12345# db.集合名称.find(&#123;&#125;,&#123;字段名称:1,...&#125;)# 参数为字段与值， 值为1表示显示， 值为0不显# 特殊： 对于_id列默认是显示的， 如果不显示需要明确设置为0# 除了_id之外的其他字段，如果不显示，不写，不能写为0db.stu.find(&#123;&#125;,&#123;_id:0,name:1,gender:1&#125;) 排序⽅法sort()， ⽤于对 集进⾏排序 12345# db.集合名称.find().sort(&#123;字段:1,...&#125;)# 参数1为升序排列# 参数-1为降序排列# 根据性别降序， 再根据年龄升序db.stu.find().sort(&#123;gender:-1,age:1&#125;) 统计个数⽅法count()⽤于统计结果集中⽂档条数 1234# db.集合名称.find(&#123;条件&#125;).count()# db.集合名称.count(&#123;条件&#125;)db.stu.find(&#123;gender:true&#125;).count()db.stu.count(&#123;age:&#123;$gt:20&#125;,gender:true&#125;) 消除重复⽅法distinct()对数据进⾏去重 12345# db.集合名称.distinct('去重字段',&#123;条件&#125;)db.stu.distinct('hometown',&#123;age:&#123;$gt:18&#125;&#125;)# 结果返回的是数组[ \"蒙古\", \"桃花岛\", \"⼤理\" ] 三、聚合aggregate聚合(aggregate)是基于数据处理的聚合管道，每个文档通过一个由多个阶段（stage）组成的管道，可以对每个阶段的管道进行分组、过滤等功能，然后经过一系列的处理，输出相应的结果。 1db.集合名称.aggregate(&#123;管道:&#123;表达式&#125;&#125;) 常用管道在mongodb中，⽂档处理完毕后， 通过管道进⾏下⼀次处理 常用管道如下： $group： 将集合中的⽂档分组， 可⽤于统计结果 $match： 过滤数据， 只输出符合条件的⽂档 $project： 修改输⼊⽂档的结构， 如重命名、 增加、 删除字段、 创建计算结果 $sort： 将输⼊⽂档排序后输出 $limit： 限制聚合管道返回的⽂档数 $skip： 跳过指定数量的⽂档， 并返回余下的⽂档 $unwind： 将数组类型的字段进⾏拆分 表达式处理输⼊⽂档并输出 语法：表达式:’$列名’ 常⽤表达式: $sum： 计算总和， $sum:1 表示以⼀倍计数 $avg： 计算平均值 $min： 获取最⼩值 $max： 获取最⼤值 $push： 在结果⽂档中插⼊值到⼀个数组中 $first： 根据资源⽂档的排序获取第⼀个⽂档数据 $last： 根据资源⽂档的排序获取最后⼀个⽂档数据 $group 将集合中的文档分组，可用于统计结果 _id表示分组的依据，使用某个字段的格式为’$字段’ 123456789# 例1：统计男生、女生的总人数db.stu.aggregate( &#123;$group: &#123; _id:'$gender', counter:&#123;$sum:1&#125; &#125; &#125;) 将集合中所有的文档分为一组 12345678910# 例2：求学生总人数，平均年龄db.stu.aggregate( &#123;$group: &#123; _id:null, counter:&#123;$sum:1&#125;, avgAge:&#123;$avg:'$age'&#125; &#125; &#125;) 对多个字段同时进行分组 12345678db.t254.aggregate( &#123;$group: &#123; _id:&#123;country:'$country',province:'$province',userid:'$userid'&#125;, count:&#123;$sum:1&#125; &#125; &#125;) $group注意点 $group对应的字典中有几个键，结果中就有几个键 分组依据需要放到_id后面 取不同的字段的值需要使用$,$gender , $age 取字典嵌套的字典中的值的时候$_id.country 能够同时按照多个键进行分组{$group:{_id:{country:&quot;$country&quot;,province:&quot;$province&quot;}}} 结果是：{_id:{country:&quot;&quot;,province:&quot;&quot;} 透视数据 push123456789# 统计不同性别的学生姓名db.stu.aggregate( &#123;$group: &#123; _id:'$gender', name:&#123;$push:'$name'&#125; &#125; &#125;) 使用$$ROOT可以将文档内容加入到结果集的数组中 12345678db.stu.aggregate( &#123;$group: &#123; _id:'$gender', name:&#123;$push:'$$ROOT'&#125; &#125; &#125;) match 用于过滤数据，只输出符合条件的文档 使用MongoDB的标准查询操作 1234567891011# 查询年龄大于20的学生db.stu.aggregate( &#123;$match:&#123;age:&#123;$gt:20&#125;&#125;&#125;)# 查询年龄大于16的男生、女生人数db.stu.aggregate( &#123;$match:&#123;age:&#123;$gt:16&#125;&#125;&#125;, &#123;$group:&#123;_id:'$gender',count:&#123;$sum:1&#125;&#125;&#125;, &#123;$project:&#123;gender:'$_id',count:1,_id:0&#125;&#125;) project 修改输入文档的结构，如重命名、增加、删除字段、创建计算结果 12345678910# 查询学生的姓名、年龄db.stu.aggregate( &#123;$project:&#123;_id:0,name:1,age:1&#125;&#125;)# 查询男生、女生人数，输出人数db.stu.aggregate( &#123;$group:&#123;_id:'$gender',count:&#123;$sum:1&#125;&#125;&#125;, &#123;$project:&#123;gender:'$_id',count:1,_id:0&#125;&#125;) 练习{ “country” : “china”, “province” : “sh”, “userid” : “a” } { “country” : “china”, “province” : “sh”, “userid” : “b” } { “country” : “china”, “province” : “sh”, “userid” : “a” } { “country” : “china”, “province” : “sh”, “userid” : “c” } { “country” : “china”, “province” : “bj”, “userid” : “da” } { “country” : “china”, “province” : “bj”, “userid” : “fa” } 需求：统计出每个country/province下的userid的数量（同一个userid只统计一次）,结果中的字段为{country:”**“，province:”**“，counter:”**“} 12345678db.t254.aggregate(&#123;$group:&#123;_id:&#123;'country':'$country','province':'$province','userid':'$userid'&#125;&#125;&#125;,&#123;$group:&#123;_id:&#123;country:\"$_id.country\",province:\"$_id.province\"&#125;,count:&#123;$sum:1&#125;&#125;&#125;,&#123;$project:&#123;country:\"$_id.country\",province:\"$_id.province\",count:1,_id:0&#125;&#125;)# 第一个group是去重userid相同的内容# 第二个group是进行分组统计# 第三个project是修改输出结果文档结构 sort 将输入文档排序后输出 12345678# 查询学生信息，按年龄升序db.stu.aggregate(&#123;$sort:&#123;age:1&#125;&#125;)# 查询男生、女生人数，按人数降序db.stu.aggregate( &#123;$group:&#123;_id:'$gender',count:&#123;$sum:1&#125;&#125;&#125;, &#123;$sort:&#123;count:-1&#125;&#125;) $limit和$skiplimit 限制聚合管道返回的文档数 12# 查询2条学生信息db.stu.aggregate(&#123;$limit:2&#125;) skip 跳过指定数量的文档，并返回余下的文档 12345678910# 查询从第3条开始的学生信息db.stu.aggregate(&#123;$skip:2&#125;)# 统计男生、女生人数，按人数升序，取第二条数据db.stu.aggregate( &#123;$group:&#123;_id:'$gender',count:&#123;$sum:1&#125;&#125;&#125;, &#123;$sort:&#123;count:1&#125;&#125;, &#123;$skip:1&#125;, &#123;$limit:1&#125;) #####注意顺序：先写skip，再写limit，这样性能更好。 $unwind 将⽂档中的某⼀个数组类型字段拆分成多条， 每条包含数组中的⼀个值 12345678# 语法：db.集合名称.aggregate(&#123;$unwind:'$字段名称'&#125;)db.t2.insert(&#123;_id:1,item:'t-shirt',size:['S','M','L']&#125;)db.t2.aggregate(&#123;$unwind:'$size'&#125;)# 结果如下：&#123; \"_id\" : 1, \"item\" : \"t-shirt\", \"size\" : \"S\" &#125;&#123; \"_id\" : 1, \"item\" : \"t-shirt\", \"size\" : \"M\" &#125;&#123; \"_id\" : 1, \"item\" : \"t-shirt\", \"size\" : \"L\" &#125; unwind练习 数据库中有一条数据：{“username”:”Alex”,”tags”:[‘C#’,’Java’,’C++’]}，如何获取该tag列表的长度？ 12345db.a1.aggregate( &#123;$unwind:'$tags'&#125;, &#123;$group:&#123;_id:'$username',count:&#123;$sum:1&#125;&#125;&#125;, &#123;$project:&#123;username:'$_id',count:1,_id:0&#125;&#125;) 以上例子中，当集合中有多条数据，并且，有部分数据的tags为’’或null时，整条数据会被丢弃，如果不想丢弃，此时需要添加：preserveNullAndEmptyArrays 属性 值为false表示丢弃属性值为空的⽂档（默认） 属性preserveNullAndEmptyArrays值为true表示保留属性值为空的⽂档 12345678db.inventory.aggregate( &#123;$unwind: &#123; path:'$字段名称', preserveNullAndEmptyArrays:&lt;boolean&gt; # 防止数据丢失 &#125; &#125;) ###创建索引 索引：以提升查询速度 db.集合.ensureIndex({属性:1}) 12345678910111213# 测试：插入10万条数据到数据库中for(i=0;i&lt;100000;i++)&#123;db.t1.insert(&#123;name:'test'+i,age:i&#125;)&#125;db.t1.find(&#123;name:'test10000'&#125;)db.t1.find(&#123;name:'test10000'&#125;).explain('executionStats') # 显示查询时间# 建立索引之后对比：# 建立语法：db.集合.ensureIndex(&#123;属性:1&#125;) # 1表示升序， -1表示降序# 升序与降序在平时查询时并无区别，只有在升级或降序排序时才有影响，即：展示时升序用的多就用1，降序用的多就用-1，如果不用升序和降序，1和-1随便选。# 具体操作：db.t1.ensureIndex(&#123;name:1&#125;)db.t1.find(&#123;name:'test10000'&#125;).explain('executionStats') #####在默认情况下创建的索引均不是唯一索引。 #####默认是以id为索引 #####创建唯一索引: db.t1.ensureIndex({“name”:1},{“unique”:true}) #####创建唯一索引并消除重复： db.t1.ensureIndex({“name”:1},{“unique”:true,”dropDups”:true}) #####建立联合索引(什么时候需要联合索引)： 需要通过多个键一起确定唯一值时 db.t1.ensureIndex({name:1,age:1}) db.collection.ensureIndex({name：1，age:1},{unique:ture}) #####查看当前集合的所有索引： db.t1.getIndexes() #####删除索引： db.t1.dropIndex(‘索引名称’) ###数据的备份和恢复 备份的语法： ​ mongodump -h dbhost -d dbname -o dbdirectory -h： 服务器地址， 也可以指定端⼝号 -d： 需要备份的数据库名称 -o： 备份的数据存放位置， 此⽬录中存放着备份出来的数据 1mongodump -h 192.168.196.128:27017 -d test1 -o ~/Desktop/test1bak 恢复语法： ​ mongorestore -h dbhost -d dbname –dir dbdirectory -h： 服务器地址 -d： 需要恢复的数据库实例 –dir： 备份数据所在位置 1mongorestore -h 192.168.196.128:27017 -d test2 --dir ~/Desktop/test1bak/test1 练习尝试将我电脑中的douban.tv1中的数据恢复到自己的电脑中，具体如何操作？ 完成上述操作后完成以下问题： 1.获取每条数据中的title，count(所有评分人数),rate(评分),country(国家)的这些字段 2.获取上述结果中的不同国家电视剧的数据量 3.获取上述结果中分数大于8分的不同国家电视剧的数据量 12345db.tv1.aggregate( &#123;$project:&#123;title:1,count:'$rating.count',score:'$rating.value',country:'$tv_category',_id:0&#125;&#125;, &#123;$match:&#123;score:&#123;$gt:8&#125;&#125;&#125;, &#123;$group:&#123;_id:'$country',count:&#123;$sum:1&#125;&#125;&#125;) pymongo实例化和插入12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# coding:utf8from pymongo import MongoClientclass TestMongo(object): def __init__(self): client = MongoClient(host=\"127.0.0.1\", port=27017) # 本机括号里可以不填 self.collection = client[\"test\"][\"t1\"] # 使用方括号的方式选择数据库和集合 def test_insert(self): # insert接收字典，返回objectId ret = self.collection.insert(&#123;\"name\": \"test10010\", \"age\": 33&#125;) print(ret) def test_insert_many(self): item_list = [&#123;\"name\": \"test1000&#123;&#125;\".format(i)&#125; for i in range(10)] # insert_many接收一个列表，列表中为所有需要插入的字典 t = self.collection.insert_many(item_list) # t.inserted_ids为所有插入的id for i in t.inserted_ids: print(i) def try_find_one(self): # find_one查找并且返回一个结果，接收一个字典形式的条件 t = self.collection.find_one(&#123;\"name\": \"test10005\"&#125;) print(t) def try_find_many(self): # find返回所有满足条件的结果，如果条件为空，则返回数据库的所有 t = self.collection.find(&#123;\"name\": \"test10005\"&#125;) # 结果是一个Cursor游标对象，是一个可迭代对象，可以类似读文件的指针 for i in t: print(i) for i in t: # 此时t中没有内容 print(i) def try_update_one(self): # update_one更新一条数据 self.collection.update_one(&#123;\"name\": \"test10005\"&#125;, &#123;\"$set\":&#123;\"name\": \"new_test10005\"&#125;&#125;) def try_update_many(self): # update_many更新全部数据 self.collection.update_many(&#123;\"name\": \"test10005\"&#125;, &#123;\"$set\": &#123;\"name\": \"new_test10005\"&#125;&#125;) def try_delete_one(self): # delete_one删除一条数据 self.collection.delete_one(&#123;\"name\": \"test10010\"&#125;) def try_delete_many(self): # delete_many删除所有满足条件的数据 self.collection.delete_many(&#123;\"name\": \"test10010\"&#125;) collection.find({}) 返回cursor，能够迭代，只能迭代一些 练习1.统计t1中所有的name的出现的次数 2.统计t1中所有的name的出现的次数中次数大于4的name 3.统计t1中所有的name的出现的次数中次数大于4的次数（只显示次数） 12345678910111213141516171819202122# coding:utf8from pymongo import MongoClientclass DouBanMongo(object): def __init__(self): client = MongoClient() self.collection = client[\"test\"][\"t1\"] def test(self): group = &#123;\"$group\": &#123;\"_id\": \"$name\", \"count\": &#123;\"$sum\": 1&#125;&#125;&#125; match = &#123;\"$match\": &#123;\"count\": &#123;\"$gt\": 4&#125;&#125;&#125; project = &#123;\"$project\": &#123;\"count\": 1, \"_id\": 0&#125;&#125; ret = self.collection.aggregate([group, match, project]) for i in ret: print(i)if __name__ == '__main__': douBanMongo = DouBanMongo() douBanMongo.test() 1、使用python向集合t5中插入1000条文档，文档的属性包括_id、name _id的值为0、1、2、3…999 name的值为’py0’、’py1’… 2、查询显示出_id为100的整倍数的文档，如100、200、300…，并将name输出 1234567891011121314151617181920212223242526272829# coding:utf8from pymongo import MongoClientclass LianXiMongo(object): def __init__(self): client = MongoClient() self.collection = client[\"test\"][\"t5\"] def test1(self): test_list = [&#123;\"_id\": i, \"name\": \"py&#123;&#125;\".format(i)&#125; for i in range(1000)] self.collection.insert_many(test_list) print(\"插入成功\") def test2(self): list = [i for i in range(1000) if i % 100 == 0 and i != 0] ret = self.collection.find(&#123;\"_id\": &#123;\"$in\": list&#125;&#125;, &#123;\"_id\": 0, \"name\": 1&#125;) for temp in ret: print(temp) def run(self): self.test1() self.test2()if __name__ == '__main__': lianXiMongo = LianXiMongo() lianXiMongo.run() mongodb mysql redis的区别和使用场景 mysql是关系型数据库，支持事物 mongodb，redis非关系型数据库，不支持事物 mysql，mongodb，redis的使用根据如何方便进行选择 希望速度快的时候，选择mongodb或者是redis 数据量过大的时候，选择频繁使用的数据存入redis，其他的存入mongodb mongodb不用提前建表建数据库，使用方便，字段数量不确定的时候使用mongodb 后续需要用到数据之间的关系，此时考虑mysql 爬虫数据去重，实现增量式爬虫 使用数据库建立关键字段（一个或者多个）建立索引进行去重 根据url地址进行去重 使用场景： url地址对应的数据不会变的情况，url地址能够唯一判别一个条数据的情况 思路 url存在redis中 拿到url地址，判断url在redis的url的集合中是够存在 存在：说明url已经被请求过，不再请求 不存在：url地址没有被请求过，请求，把该url存入redis的集合中 布隆过滤器 使用多个加密算法加密url地址，得到多个值 往对应值的位置把结果设置为1 新来一个url地址，一样通过加密算法生成多个值 如果对应位置的值全为1，说明这个url地址已经抓过 否则没有抓过，就把对应位置的值设置为1 布隆过滤器结果是有概率的，判断结果不存在就一定不存在，判断存在也可能不存在 根据数据本身进行去重 选择特定的字段，使用加密算法（md5，sha1）讲字段进行加密，生成字符串，存入redis的集合中 后续新来一条数据，同样的方法进行加密，如果得到的字符串在redis中存在，说明数据存在，对数据进行更新，否则说明数据不存在，直接插入","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"http://yoursite.com/tags/mongodb/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"pycharm快捷键大全","slug":"others/pycharm快捷键大全","date":"2020-05-16T01:05:57.000Z","updated":"2020-05-16T01:05:56.253Z","comments":true,"path":"2020/05/16/others/pycharm快捷键大全/","link":"","permalink":"http://yoursite.com/2020/05/16/others/pycharm%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%A4%A7%E5%85%A8/","excerpt":"","text":"#pycharm快捷键大全 1、编辑（Editing）Ctrl + Space 基本的代码完成（类、方法、属性） Ctrl + Alt + Space 快速导入任意类 Ctrl + Shift + Enter 语句完成 Ctrl + P 参数信息（在方法中调用参数） Ctrl + Q 快速查看文档 F1 Web帮助文档主页 Shift + F1 选中对象的Web帮助文档 Ctrl + 悬浮/单击鼠标左键 简介/进入代码定义 Ctrl + Z 撤销上次操作 Ctrl + Shift + Z 重做,恢复上次的撤销 Ctrl + F1 显示错误描述或警告信息 Alt + Insert 自动生成代码 Ctrl + O 重新方法 Ctrl + Alt + T 选中 Ctrl + / 行注释/取消注释 Ctrl + Shift + / 块注释 Ctrl + W 选中增加的代码块 Ctrl + Shift + W 回到之前状态 Ctrl + Shift + ]/[ 选定代码块结束、开始 Alt + Enter 快速修正 Ctrl + Alt + L 代码格式化 Ctrl + Alt + O 优化导入 Ctrl + Alt + I 自动缩进 Tab / Shift + Tab 缩进、不缩进当前行 Ctrl+X/Shift+Delete 剪切当前行或选定的代码块到剪贴板 Ctrl+C/Ctrl+Insert 复制当前行或选定的代码块到剪贴板 Ctrl+V/Shift+Insert 从剪贴板粘贴 Ctrl + Shift + V 从最近的缓冲区粘贴 Ctrl + D 复制选定的区域或行 Ctrl + Y 删除选定的行 Ctrl + Shift + J 添加智能线 Ctrl + Enter 智能线切割 Shift + Enter 另起一行 Ctrl + Shift + U 在选定的区域或代码块间切换 Ctrl + Delete 删除到字符结束 Ctrl + Backspace 删除到字符开始 Ctrl + Numpad+/- 展开/折叠代码块（当前位置：函数、注释等） Ctrl + Shift + Numpad+/- 展开/折叠所有代码块 Ctrl + F4 关闭运行的选项卡 2、查找/替换(Search/Replace)F3 下一个 Shift + F3 前一个 Ctrl + R 替换 Ctrl + Shift + R 全局替换 Ctrl + Shift + F 全局查找（可以在整个项目中查找某个字符串什么的，如查找某个函数名） 连续敲击两次Shift键 查找函数 3、运行(Running)Alt + Shift + F10 运行模式配置 Alt + Shift + F9 调试模式配置 Shift + F10 运行 Shift + F9 调试 Ctrl + Shift + F10 运行编辑器配置 Ctrl + Alt + R 运行manage.py任务 4、调试(Debugging)F8 跳过 F7 进入 Shift + F8 退出 Alt + F9 运行游标 Alt + F8 验证表达式 Ctrl + Alt + F8 快速验证表达式 F9 恢复程序 Ctrl + F8 断点开关 Ctrl + Shift + F8 查看断点 5、导航(Navigation)Ctrl + N 跳转到类 Ctrl + Shift + N 跳转到符号 Alt + Right/Left 跳转到下一个、前一个编辑的选项卡（代码文件） Alt + Up/Down跳转到上一个、下一个方法 F12 回到先前的工具窗口 Esc 从工具窗口回到编辑窗口 Shift + Esc 隐藏运行的、最近运行的窗口 Ctrl + Shift + F4 关闭主动运行的选项卡 Ctrl + G 查看当前行号、字符号 Ctrl + E 在当前文件弹出最近使用的文件列表 Ctrl+Alt+Left/Right 后退、前进 Ctrl+Shift+Backspace 导航到最近编辑区域（差不多就是返回上次编辑的位置） Alt + F1 查找当前文件或标识 Ctrl+B / Ctrl+Click 跳转到声明 Ctrl + Alt + B 跳转到实现 Ctrl + Shift + I 查看快速定义 Ctrl + Shift + B 跳转到类型声明 Ctrl + U 跳转到父方法、父类 Alt + Up/Down 跳转到上一个、下一个方法 Ctrl + ]/[ 跳转到代码块结束、开始 Ctrl + F12 弹出文件结构 Ctrl + H 类型层次结构 Ctrl + Shift + H 方法层次结构 Ctrl + Alt + H 调用层次结构 F2 / Shift + F2 下一条、前一条高亮的错误 F4 / Ctrl + Enter 编辑资源、查看资源 Alt + Home显示导航条F11 书签开关 Ctrl + Shift + F11 书签助记开关 Ctrl + #[0-9] 跳转到标识的书签 Shift + F11 显示书签 6、搜索相关(Usage Search)Alt + F7/Ctrl + F7 文件中查询用法 Ctrl + Shift + F7 文件中用法高亮显示 Ctrl + Alt + F7 显示用法 7、重构(Refactoring)Alt + Delete 安全删除 Shift + F6 重命名文件 Ctrl + F6 更改签名 Ctrl + Alt + N 内联 Ctrl + Alt + M 提取方法 Ctrl + Alt + V 提取属性 Ctrl + Alt + F 提取字段 Ctrl + Alt + C 提取常量 Ctrl + Alt + P 提取参数 8、控制VCS/Local HistoryCtrl + K 提交项目 Ctrl + T 更新项目 Alt + Shift + C 查看最近的变化 Alt + BackQuote(‘) VCS快速弹出 9、模版(Live Templates)Ctrl + Alt + J 当前行使用模版 Ctrl + J 插入模版 10、基本(General)Alt + #[0-9] 打开相应的工具窗口 Ctrl + Alt + Y 同步 Ctrl + Shift + F12 最大化编辑开关 Alt + Shift + F 添加到最喜欢 Alt + Shift + I 根据配置检查当前文件 Ctrl + BackQuote(‘) 快速切换当前计划 Ctrl + Alt + S 打开设置页 Ctrl + Shift + A 查找编辑器里所有的动作 Ctrl + Tab 在窗口间进行切换","categories":[{"name":"其他","slug":"其他","permalink":"http://yoursite.com/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"pycharm","slug":"pycharm","permalink":"http://yoursite.com/tags/pycharm/"},{"name":"快捷键","slug":"快捷键","permalink":"http://yoursite.com/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"http://yoursite.com/categories/%E5%85%B6%E4%BB%96/"}]},{"title":"python高级编程和异步IO并发编程","slug":"python/Python高级编程和异步IO并发编程","date":"2020-05-16T01:05:57.000Z","updated":"2020-05-16T02:19:19.430Z","comments":true,"path":"2020/05/16/python/Python高级编程和异步IO并发编程/","link":"","permalink":"http://yoursite.com/2020/05/16/python/Python%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E5%92%8C%E5%BC%82%E6%AD%A5IO%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","excerpt":"","text":"第二章 一切皆对象函数和类也是对象，属于python的一等公民 函数和类可以赋值给一个变量 函数和类可以添加到集合对象中 函数和类可以作为参数传递给函数 可以当做函数的返回值 type、class、object之间的关系type→class→obj 例如：type→int→1 例如： 123456class Student: passstu = Student()print(type(stu))print(type(Student)) 输出： 12&lt;class '__main__.Student'&gt;&lt;class 'type'&gt; object是最顶层的基类 第三章 魔法函数__getitem__12345678910111213141516class Company(object): def __init__(self, employee_list): self.employee = employee_list def __getitem__(self, item): return self.employee[item]company = Company([\"tom\", \"bob\", \"jane\"])company1 = company[:2]print(len(company))for em in company1: print(em) __repr__如果在一个类中定义了__repr__方法，那么在开发模式下，输出对象显示该方法的返回值 __str__如果一个类中定义了__str__方法，那么在打印 对象 时，默认输出该方法的返回值。 __abs__绝对值 __add__+ __len__显示长度，效率很高 1234567891011class Company(object): def __init__(self, employee_list): self.employee = employee_list def __len__(self): return len(self.employee)company = Company([\"tom\", \"bob\", \"jane\"])print(len(company)) __mro__打印类的属性和方法的查找顺序 __dict__显示类或对象的所以属性和方法，也可以通过它添加属性和方法 __enter__、__exit__实现上下文管理器，见第四章的上下文管理器 __getattr__、__getattribute____getattr__：当查找的属性不存在时，会进入__getattr__ __getattribute__:只要调用属性，就会先进入__getattribute__ 123456789101112131415class User: def __init__(self, info=&#123;&#125;): self.info = info # 方法里的参数item就是对应的属性 def __getattr__(self, item): return self.info[item] # def __getattribute__(self, item): # return \"bobby\"if __name__ == \"__main__\": user = User(info=&#123;\"company_name\": \"imooc\", \"name\": \"bobby\"&#125;) print(user.test) 第四章 深入类和对象鸭子类型和多态所有类实现了一个共同的方法，这种方法叫做鸭，这些类就可以归为一种类型，都是鸭子类型，他们都可以调用这个鸭方法。所以也可以理解为，某一个类只要实现了某种魔法方法，那么这个类就是这个方法对应的某种类型。例如：某个类实现了__iter__方法，那么这个类就是可迭代类型。 而每个类的这个鸭方法可能又不一样，就叫做多态。 举例：list、tuple、set都是可迭代类型，他们都有魔法方法__iter__使他们成为可迭代对象，可是它们具体的__iter__方法可能又不一样。 在python中传参数时经常是传一种类型就可以了，而不是一定要传某种对象，例如list的extend方法，传入可迭代类型就可以，而不是一定要传入list对象。 抽象基类(abc模块)主要的两个作用： 1、可以使用isinstance判断某个对象的类型 12from collections.abc import Sizedisinstance(com, Sized) 2、强制指定某个子类必须要实现某个方法 12345678910import abcclass CacheBase(metaclass=abc.ABCMeta): @abc.abstractmethod def get(self, key): pass @abc.abstractmethod def set(self, key, value): pass 使用上述抽象基类的方法后，如果子类没有实现这些方法，在实例化时就会抛出异常 一般不推荐使用抽象基类，因为如果使用抽象基类，容易代码设计过度，导致一些不必要的麻烦，如果要通过继承实现某些方法，推荐用mixin，或实现某些魔法方法。 模拟一个抽象基类： 12345class CacheBase(): def get(self, key): raise NotImplementedError def set(self, key, value): raise NotImplementedError 上述是模拟抽象基类的方法，可以在子类继承后，如果没有重写这些方法，那么在使用这些方法时就会抛出异常。 isinstance和type判断一个变量的类型时尽量用isinstance，因为isinstance在判断时会把继承关系也判断进去，而如果用type则会出现误差。 数据封装和私有属性123456789101112131415from chapter04.class_method import Dateclass User: def __init__(self, birthday): self.__birthday = birthday def get_age(self): # 返回年龄 return 2018 - self.__birthday.yearif __name__ == \"__main__\": user = User(Date(1990, 2, 1)) print(user._User__birthday) print(user.get_age()) python对象的自省机制自省是通过一定的机制查询到对象的内部结构 123456789101112131415161718192021class Person: \"\"\"人\"\"\" name = \"user\"class Student(Person): def __init__(self, scool_name): self.scool_name = scool_nameif __name__ == \"__main__\": user = Student(\"慕课网\") # 通过__dict__查询属性 print(user.__dict__) # 也可以通过__dict__添加属性 user.__dict__[\"school_addr\"] = \"北京市\" print(user.school_addr) print(Person.__dict__) print(user.name) a = [1, 2] # dir函数比__dict__更加强大，列表使用__dict__会报错，dir函数则不会 print(dir(a)) super函数super函数的执行顺序是根据__mro__的继承顺序，如果根据__mro__的顺序，其中的一个类C没有super()方法，那么C后面的继承就会中断，只继承C和C前面的 12345678910111213141516171819202122class A: def __init__(self): print(\"A\")class B(A): def __init__(self): print(\"B\") super().__init__()class C(A): def __init__(self): print(\"C\") # super().__init__()class D(B, C): def __init__(self): print(\"D\") super(D, self).__init__()if __name__ == \"__main__\": print(D.__mro__) d = D() 执行结果 1234(&lt;class '__main__.D'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, &lt;class 'object'&gt;)DBC mixin混合模式mixin模式特点 Mixin类功能单一 不和基类关联，可以和任意基类组合， 基类可以不和mixin关联就能初始化成功 在mixin中不要使用super这种用法 异常处理和上下文管理器1234567891011121314151617181920212223242526272829303132333435363738394041def exe_try(): try: print(\"code started\") raise KeyError return 1 except KeyError as e: print(\"key error\") return 2 else: print(\"other error\") return 3 finally: print(\"finally\") return 4# 以上代码执行结果是：code startedkey errorfinally4# 如果注释了finally中的return 4，那么执行结果就会变成code startedkey errorfinally2# 上下文管理器协议class Sample: def __enter__(self): print(\"enter\") # 获取资源 return self # 此处一定要return self def __exit__(self, exc_type, exc_val, exc_tb): # 释放资源 print(\"exit\") def do_something(self): print(\"doing something\")with Sample() as sample: sample.do_something() 简化上下文管理器12345678910111213import contextlib@contextlib.contextmanagerdef file_open(file_name): print(\"file open\") # yield前的代码先执行，相当于上面的__enter__内的内容 yield &#123;&#125; # yield后的代码最后执行，相当于上面的__exit__内的内容 print(\"file end\")with file_open(\"bobby.txt\") as f_opened: # with内执行的代码(也就是下面的代码)，相当于上面的do_something内的内容 print(\"file processing\") 第五章 自定义序列类序列类型区分区分维度1： 容器序列（list、tuple、deque）：存放的数据可以是任意类型的。 扁平序列(str、bytes、bytearray、array.array)：只能存放一种类型的数据。 区分维度2： 可变序列：list， deque，bytearray、array。 不可变序列：str、tuple、bytes。 +、+=、extend、append1234567891011from collections import abc# +号两侧必须是同种类型，相加后返回一个新的序列a = [1, 2]c = a + [3, 4]# 就地加，不会产生新的序列，和extend相同，所相加的为可迭代类型即可a += (3, 4)a.extend(range(3))a.append((1, 2))print(a) 切片会产生一个新的序列 12345678910111213141516171819202122232425262728293031# 模式[start:end:step]\"\"\" 其中，第一个数字start表示切片开始位置，默认为0； 第二个数字end表示切片截止（但不包含）位置（默认为列表长度）； 第三个数字step表示切片的步长（默认为1）。 当start为0时可以省略，当end为列表长度时可以省略， 当step为1时可以省略，并且省略步长时可以同时省略最后一个冒号。 另外，当step为负整数时，表示反向切片，这时start应该比end的值要大才行。\"\"\"aList = [3, 4, 5, 6, 7, 9, 11, 13, 15, 17]print(aList[::]) # 返回包含原列表中所有元素的新列表print(aList[::-1]) # 返回包含原列表中所有元素的逆序列表print(aList[::2]) # 隔一个取一个，获取偶数位置的元素print(aList[1::2]) # 隔一个取一个，获取奇数位置的元素print(aList[3:6]) # 指定切片的开始和结束位置aList[0:100] # 切片结束位置大于列表长度时，从列表尾部截断aList[100:] # 切片开始位置大于列表长度时，返回空列表aList[len(aList):] = [9] # 在列表尾部增加元素aList[:0] = [1, 2] # 在列表头部插入元素aList[3:3] = [4] # 在列表中间位置插入元素aList[:3] = [1, 2] # 替换列表元素，等号两边的列表长度相等aList[3:] = [4, 5, 6] # 等号两边的列表长度也可以不相等aList[::2] = [0] * 3 # 隔一个修改一个print(aList)aList[::2] = ['a', 'b', 'c'] # 隔一个修改一个aList[::2] = [1, 2] # 此条会抛异常，左侧切片不连续，等号两边列表长度必须相等aList[:3] = [] # 删除列表中前3个元素del aList[:3] # 切片元素连续del aList[::2] # 切片元素不连续，隔一个删一个 实现一个可切片的序列类 123456789101112131415161718192021222324252627282930313233343536373839import numbersclass Group: # 支持切片操作 def __init__(self, group_name, company_name, staffs): self.group_name = group_name self.company_name = company_name self.staffs = staffs def __reversed__(self): # 实现反转 self.staffs.reverse() def __getitem__(self, item): # 实现可切片 cls = type(self) if isinstance(item, slice): # 如果传入的是切片 return cls(group_name=self.group_name, company_name=self.company_name, staffs=self.staffs[item]) elif isinstance(item, numbers.Integral): # 如果传入的是索引 return cls(group_name=self.group_name, company_name=self.company_name, staffs=[self.staffs[item]]) def __len__(self): # 实现长度 return len(self.staffs) def __iter__(self): # 实现可遍历 return iter(self.staffs) def __contains__(self, item): # 实现if···in···： if item in self.staffs: return True else: return Falsestaffs = [\"bobby1\", \"imooc\", \"bobby2\", \"bobby3\"]group = Group(company_name=\"imooc\", group_name=\"user\", staffs=staffs)reversed(group)for user in group: print(user)group[0:2]group[0] bisect管理可排序序列用来处理已排序的序列，用来维持已排序的序列，升序 12345678910111213141516import bisectfrom collections import deque# 用来处理已排序的序列，用来维持已排序的序列， 升序# 二分查找inter_list = list()bisect.insort(inter_list, 3)bisect.insort(inter_list, 2)bisect.insort(inter_list, 5)bisect.insort(inter_list, 1)bisect.insort(inter_list, 6)print(bisect.bisect_left(inter_list, 3))print(bisect.bisect_left(inter_list, 3))# 学习成绩print(inter_list) 什么时候我们不该使用列表array(数组)：数组只能存放指定的数据类型，但是效率要比列表高很多，所以如果存放的都是一种数据，建议使用array 1234567# array, deque# 数组import array#array和list的一个重要区别， array只能存放指定的数据类型my_array = array.array(\"i\")my_array.append(1)my_array.append(\"abc\") https://docs.python.org/3.6/library/array.html 列表推导式、生成器表达式、字典推导式、集合推导式123456789101112131415161718192021222324# 列表推导式的效率比较高old_list = [i for i in range(21) if i % 2 == 1]# 用列表推导式把列表嵌套列表变成一个列表a_list = [[1,2], [3,4], [5,6], [7,8]]b_list = [i for j in a_list for i in j]print(b_list)&gt;&gt;[1, 2, 3, 4, 5, 6, 7, 8]def hadle_item(item): return item * itemold_list = [hadle_item(i) for i in range(21) if i % 2 == 1]# 生成器表达式old_gen = (i for i in range(21) if i % 2 == 1)# 字典推导式my_dict = &#123;\"bobby1\":22, \"bobby2\": 23, \"bobby3\": 25&#125;# 使用字典推导式把上面的字典key和value进行反转new_dict = &#123;value:key for key,value in my_dict.item()&#125;# 集合推导式# my_set = set(my_dict.keys()) 此方法也可实现，但是没有集合推导式灵活my_set = &#123;key for key,value in my_dict.item()&#125; 第六章 深入python的set和dictdict的常用方法1234567891011121314151617181920212223a = &#123;\"bobby1\": &#123;\"company\": \"imooc\"&#125;, \"bobby2\": &#123;\"company\": \"imooc2\"&#125; &#125;# clear清空字典里的全部数据a.clear()# copy, 返回浅拷贝new_dict = a.copy()new_dict[\"bobby1\"][\"company\"] = \"imooc3\"# formkeys，向字典中添加数据，key是new_list中的各个元素，value是添加的默认值new_list = [\"bobby1\", \"bobby2\"]new_dict = dict.fromkeys(new_list, &#123;\"company\": \"imooc\"&#125;)# setdefault,把key和value添加到字典中，并且返回的是valueget_value = a.setdefault(\"tom\", \"alibaba\")# update，更新字典，可以以3中方式添加数据new_dict.update(&#123;\"tom1\": \"1\"&#125;)new_dict.update(tom2=\"2\", tom3=\"3\")new_dict.update([(\"tom4\", \"4\"),])new_dict.update(((\"bobby\", \"imooc\"),)) dict的子类UserDict: 使用dict的子类，可以继承UserDict，不要继承于dict 123456789from collections import UserDictclass Mydict(UserDict): def __setitem__(self, key, value): super().__setitem__(key, value * 2)my_dict = Mydict(one=1)# my_dict[\"one\"] = 1print(my_dict) defaultdict：子类继承于defaultdict后，如果取值没有，那么就会执行对应的__miss__方法，默认的defaultdict如果取值没有，则会添加空字典进字典，并且返回空字典 12345678910from collections import defaultdictmy_dict = defaultdict(dict)my_value = my_dict[\"bobby\"]print(my_value)print(my_dict)# 执行结果&#123;&#125;defaultdict(&lt;class 'dict'&gt;, &#123;'bobby': &#123;&#125;&#125;) set、fronzensetset集合 fronzenset (不可变集合) 无序， 不重复 12345678910111213141516171819s = set('abcdee')s = &#123;'a', 'b', 'c'&#125;# s = frozenset(\"abcde\") #frozenset可以作为dict的key，因为frozenst是不可变的# print(s)# set性能很高# | &amp; - #集合运算# 向set添加数据another_set = set(\"cef\")re_set = s.difference(another_set)re_set = s - another_setre_set = s &amp; another_setre_set = s | another_setprint(re_set)print(s.issubset(re_set)) # 判断re_set是否是s的子集if \"c\" in re_set: print (\"i am in set\") dict和set的实现原理 dict查找的性能远远大于list 在list中随着list数据的增大 查找时间会增大 在dict中查找元素不会随着dict的增大而增大 dict的key或者set的值 都必须是可以hash的，不可变对象 都是可hash的， str， fronzenset， tuple，自己实现的类__hash__ dict的内存花销大，但是查询速度快， 自定义的对象 或者python内部的对象都是用dict包装的 dict的存储顺序和元素添加顺序有关 添加数据有可能改变已有数据的顺序 第七章 对象引用、可变性和垃圾回收一个经典的错误1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253def add(a, b): a += b return aclass Company: def __init__(self, name, staffs=[]): self.name = name self.staffs = staffs def add(self, staff_name): self.staffs.append(staff_name) def remove(self, staff_name): self.staffs.remove(staff_name)if __name__ == \"__main__\": com1 = Company(\"com1\", [\"bobby1\", \"bobby2\"]) com1.add(\"bobby3\") com1.remove(\"bobby1\") print(com1.staffs) com2 = Company(\"com2\") com2.add(\"bobby\") print(com2.staffs) print(Company.__init__.__defaults__) com3 = Company(\"com3\") com3.add(\"bobby5\") # 因为初始化时用，staffs=[]，在内存中是同一个地址下的同一个列表，所以com2,com3的staffs是同一个。 print(com2.staffs) print(com3.staffs) print(com2.staffs is com3.staffs) a = 1 b = 2 c = add(a, b) print(c) print(a, b) a = [1, 2] b = [3, 4] c = add(a, b) print(c) print(a, b) a = (1, 2) b = (3, 4) c = add(a, b) print(c) print(a, b) 第八章 元类编程property属性123456789101112131415161718192021222324252627282930from datetime import date, datetimeclass User: def __init__(self, name, birthday): self.name = name self.birthday = birthday self._age = 0 # def get_age(self): # return datetime.now().year - self.birthday.year @property def age(self): return datetime.now().year - self.birthday.year @age.setter def age(self, value): self._age = value @age.deleter def age(self): del self._ageif __name__ == \"__main__\": user = User(\"bobby\", date(year=1987, month=1, day=1)) user.age = 30 print(user._age) print(user.age) 属性描述符获取的属性如果是一个变量，那么用getattr函数就比较方便，例如：getattr(user, name) 123456789101112131415161718192021222324252627282930313233343536373839404142'''如果user是某个类的实例，那么user.age（以及等价的getattr(user,’age’)）首先调用__getattribute__。如果类定义了__getattr__方法，那么在__getattribute__抛出 AttributeError 的时候就会调用到__getattr__，而对于描述符(__get__）的调用，则是发生在__getattribute__内部的。user = User(), 那么user.age 顺序如下：（1）如果“age”是出现在User或其基类的__dict__中， 且age是data descriptor(数据属性描述符)， 那么调用其__get__方法, 否则（2）如果“age”出现在user的__dict__中， 那么直接返回 obj.__dict__[‘age’]， 否则（3）如果“age”出现在User或其基类的__dict__中 （3.1）如果age是non-data descriptor（非数据属性描述符），那么调用其__get__方法， 否则 （3.2）返回 __dict__[‘age’]（4）如果User有__getattr__方法，调用__getattr__方法，否则（5）抛出AttributeError只要实现__get__、set、__delete__方法中的一个就可以认为是属性描述符；只实现__get__方法的对象是非数据属性描述符，在初始化之后它们只能被读取；同时实现__get__和__set__的对象是数据属性描述符，这种属性是可读写的。'''class IntField: #数据属性描述符 def __get__(self, instance, owner): # 获取属性 return self.value def __set__(self, instance, value): # 设置属性 if not isinstance(value, numbers.Integral): raise ValueError(\"int value need\") if value &lt; 0: raise ValueError(\"positive value need\") self.value = value def __delete__(self, instance): # 删除属性 passclass NonDataIntField: #非数据属性描述符 def __get__(self, instance, owner): return self.valueclass User: age = IntField() # age = NonDataIntField() 自定义元类什么是元类， 元类是创建类的类 对象&lt;-class(对象)&lt;-type 创建类的方法有三种： 方法一： 通过函数动态创建 1234567891011def create_class(name): if name == \"user\": class User: def __str__(self): return \"user\" return User elif name == \"company\": class Company: def __str__(self): return \"company\" return Company 方法二： 通过type创建，类也是对象，type是创建类的类 1234567891011def say(self): return \"i am user\" # return self.nameclass BaseClass(): def answer(self): return \"i am baseclass\"#type动态创建类# User = type(\"User\", (), &#123;&#125;)User = type(\"User\", (BaseClass, ), &#123;\"name\":\"user\", \"say\":say&#125;) 方法三： metaclass python中的类的实例化过程：会首先寻找metaclass，通过metaclass里的__new__方法实例化一个实例对象，如果自己的metaclass找不到，会向上一级寻找父类的metaclass 123456789class MetaClass(type): def __new__(cls, *args, **kwargs): return super().__new__(cls, *args, **kwargs)class User(metaclass=MetaClass): def __init__(self, name): self.name = name def __str__(self): return \"user\" 通过元类实现ORM123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114# 需求import numbersclass Field: passclass IntField(Field): # 数据描述符 def __init__(self, db_column, min_value=None, max_value=None): self._value = None self.min_value = min_value self.max_value = max_value self.db_column = db_column if min_value is not None: if not isinstance(min_value, numbers.Integral): raise ValueError(\"min_value must be int\") elif min_value &lt; 0: raise ValueError(\"min_value must be positive int\") if max_value is not None: if not isinstance(max_value, numbers.Integral): raise ValueError(\"max_value must be int\") elif max_value &lt; 0: raise ValueError(\"max_value must be positive int\") if min_value is not None and max_value is not None: if min_value &gt; max_value: raise ValueError(\"min_value must be smaller than max_value\") def __get__(self, instance, owner): return self._value def __set__(self, instance, value): if not isinstance(value, numbers.Integral): raise ValueError(\"int value need\") if value &lt; self.min_value or value &gt; self.max_value: raise ValueError(\"value must between min_value and max_value\") self._value = valueclass CharField(Field): def __init__(self, db_column, max_length=None): self._value = None self.db_column = db_column if max_length is None: raise ValueError(\"you must spcify max_lenth for charfiled\") self.max_length = max_length def __get__(self, instance, owner): return self._value def __set__(self, instance, value): if not isinstance(value, str): raise ValueError(\"string value need\") if len(value) &gt; self.max_length: raise ValueError(\"value len excess len of max_length\") self._value = valueclass ModelMetaClass(type): def __new__(cls, name, bases, attrs, **kwargs): if name == \"BaseModel\": return super().__new__(cls, name, bases, attrs, **kwargs) fields = &#123;&#125; for key, value in attrs.items(): if isinstance(value, Field): fields[key] = value attrs_meta = attrs.get(\"Meta\", None) _meta = &#123;&#125; db_table = name.lower() if attrs_meta is not None: table = getattr(attrs_meta, \"db_table\", None) if table is not None: db_table = table _meta[\"db_table\"] = db_table attrs[\"_meta\"] = _meta attrs[\"fields\"] = fields del attrs[\"Meta\"] return super().__new__(cls, name, bases, attrs, **kwargs)class BaseModel(metaclass=ModelMetaClass): def __init__(self, *args, **kwargs): for key, value in kwargs.items(): setattr(self, key, value) return super().__init__() def save(self): fields = [] values = [] for key, value in self.fields.items(): db_column = value.db_column if db_column is None: db_column = key.lower() fields.append(db_column) value = getattr(self, key) values.append(str(value)) sql = \"insert &#123;db_table&#125;(&#123;fields&#125;) value(&#123;values&#125;)\".format(db_table=self._meta[\"db_table\"], fields=\",\".join(fields), values=\",\".join(values)) passclass User(BaseModel): name = CharField(db_column=\"name\", max_length=10) age = IntField(db_column=\"age\", min_value=1, max_value=100) class Meta: db_table = \"user\"if __name__ == \"__main__\": user = User(name=\"bobby\", age=28) # user.name = \"bobby\" # user.age = 28 user.save() 第九章 迭代器和生成器可迭代对象和迭代器list是可迭代对象，而不是迭代器 实现__item__方法即是可迭代对象，而__item__方法必须要return一个迭代器 实现__item__方法和__next__方法即是迭代器，而__item__方法要return self，__next__方法实现遍历。 在创建一个可迭代对象时尽量不要定义__next__方法，要单独创建一个迭代器，然后在这个可迭代对象的__item__方法里return这个迭代器即可，分开维护比较好。 12345678910111213141516171819202122232425262728293031323334from collections.abc import Iteratorclass Company(object): # 是可迭代对象 def __init__(self, employee_list): self.employee = employee_list def __iter__(self): return MyIterator(self.employee)class MyIterator(Iterator): # 是迭代器，因为继承了Iterator，所以无需再写__item__方法 def __init__(self, employee_list): self.iter_list = employee_list self.index = 0 def __next__(self): #真正返回迭代值的逻辑 try: word = self.iter_list[self.index] except IndexError: raise StopIteration self.index += 1 return wordif __name__ == \"__main__\": company = Company([\"tom\", \"bob\", \"jane\"]) my_itor = iter(company) # while True: # try: # print (next(my_itor)) # except StopIteration: # pass for item in company: print (item) 生成器调用生成器函数，返回的是一个生成器的对象 生成器的应用：大文件读取 1234567891011121314151617181920# 500G, 特殊 一行def myreadlines(f, newline): buf = \"\" while True: while newline in buf: pos = buf.index(newline) yield buf[:pos] buf = buf[pos + len(newline):] chunk = f.read(4096) if not chunk: # 说明已经读到了文件结尾 yield buf break buf += chunkwith open(\"input.txt\") as f: for line in myreadlines(f, \"&#123;|&#125;\"): print(line) 第十章 python socket编程客户端12345678import socketclient = socket.socket(socket.AF_INET, socket.SOCK_STREAM)client.connect(('127.0.0.1', 8000))client.send(\"bobby\".encode(\"utf8\"))data = client.recv(1024)print(data.decode(\"utf8\"))client.close() 服务端12345678910111213141516171819import socketimport threadingserver = socket.socket(socket.AF_INET, socket.SOCK_STREAM)server.bind(('0.0.0.0', 8000))server.listen()def handle_sock(sock, addr): while True: data = sock.recv(1024) print(data.decode(\"utf8\")) re_data = input() sock.send(re_data.encode(\"utf8\"))while True: sock, addr = server.accept() client_thread = threading.Thread(target=handle_sock, args=(sock, addr)) client_thread.start() 第十一章 多线程、多进程和线程池编程GIL锁(全局解释器锁) Python语言和GIL没有半毛钱关系。仅仅是由于历史原因在Cpython虚拟机(解释器)，难以移除GIL。 GIL：全局解释器锁。每个线程在执行的过程都需要先获取GIL，保证同一时刻只有一个线程可以执行代码。 线程释放GIL锁的情况： 在IO操作等可能会引起阻塞的system call之前,可以暂时释放GIL,但在执行完毕后,必须重新获取GIL Python 3.x使用计时器（执行时间达到阈值后，当前线程释放GIL）或Python 2.x，tickets计数达到100 Python使用多进程是可以利用多核的CPU资源的。 多线程爬取比单线程性能有提升，因为遇到IO阻塞会自动释放GIL锁 多线程编程方法一： 12345678910111213141516171819202122232425import timeimport threadingdef get_detail_html(url): print(\"get detail html started\") time.sleep(2) print(\"get detail html end\")def get_detail_url(url): print(\"get detail url started\") time.sleep(4) print(\"get detail url end\") if __name__ == \"__main__\": thread1 = GetDetailHtml(\"get_detail_html\") thread2 = GetDetailUrl(\"get_detail_url\") # thread1.setDaemon() # 设置为守护线程，即主线程结束，则子线程即结束 # thread2.setDaemon() start_time = time.time() thread1.start() thread2.start() thread1.join() # 子线程结束后再运行主线程 thread2.join() #当主线程退出的时候， 子线程kill掉 print (\"last time: &#123;&#125;\".format(time.time()-start_time)) 方法二： 1234567891011121314151617181920212223class GetDetailHtml(threading.Thread): def __init__(self, name): super().__init__(name=name) def run(self): print(\"get detail html started\") time.sleep(2) print(\"get detail html end\")class GetDetailUrl(threading.Thread): def __init__(self, name): super().__init__(name=name) def run(self): print(\"get detail url started\") time.sleep(4) print(\"get detail url end\") if __name__ == \"__main__\": thread1 = GetDetailHtml(\"get_detail_html\") thread2 = GetDetailUrl(\"get_detail_url\") thread1.start() thread2.start() 线程间通信-共享变量和Queue从其他文件导入全局变量时尽量使用： 12from capter import variablesvariables.detail_url_list 而不要使用： 1from capter.variables import detail_url_list Queue用例： 123456789101112131415161718192021222324252627282930313233from queue import Queueimport timeimport threadingdef get_detail_html(queue): #爬取文章详情页 while True: url = queue.get() # for url in detail_url_list: print(\"get detail html started\") time.sleep(2) print(\"get detail html end\")def get_detail_url(queue): # 爬取文章列表页 while True: print(\"get detail url started\") time.sleep(4) for i in range(20): queue.put(\"http://projectsedu.com/&#123;id&#125;\".format(id=i)) print(\"get detail url end\") if __name__ == \"__main__\": detail_url_queue = Queue(maxsize=1000) thread_detail_url = threading.Thread(target=get_detail_url, args= (detail_url_queue,)) html_thread = threading.Thread(target=get_detail_html, args=(detail_url_queue,)) thread_detail_url.start() html_thread.start() # 以下两个是在不同地方成对使用，detail_url_queue.join()是从queue的角度阻塞主线程，当我们想要取消阻塞时，即达到我们想要的某个条件时，调用detail_url_queue.task_done()即可取消阻塞 detail_url_queue.task_done() detail_url_queue.join() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#通过queue的方式进行线程间同步from queue import Queueimport timeimport threadingdef get_detail_html(queue): #爬取文章详情页 while True: url = queue.get() # for url in detail_url_list: print(\"get detail html started\") time.sleep(2) print(\"get detail html end\")def get_detail_url(queue): # 爬取文章列表页 while True: print(\"get detail url started\") time.sleep(4) for i in range(20): queue.put(\"http://projectsedu.com/&#123;id&#125;\".format(id=i)) print(\"get detail url end\")#1. 线程通信方式- 共享变量if __name__ == \"__main__\": detail_url_queue = Queue(maxsize=1000) thread_detail_url = threading.Thread(target=get_detail_url, args=(detail_url_queue,)) for i in range(10): html_thread = threading.Thread(target=get_detail_html, args=(detail_url_queue,)) html_thread.start() # # thread2 = GetDetailUrl(\"get_detail_url\") start_time = time.time() # thread_detail_url.start() # thread_detail_url1.start() # # thread1.join() # thread2.join() detail_url_queue.task_done() detail_url_queue.join() #当主线程退出的时候， 子线程kill掉 print (\"last time: &#123;&#125;\".format(time.time()-start_time)) 12# 优先级队列(后插入的先取出)from queue import PriorityQueue 线程同步 - Lock、RLockLock锁 因为上锁和解锁需要时间，所以锁会影响性能 可能会出现死锁 12345678910111213141516171819202122232425262728293031323334from threading import Lock total = 0lock = Lock()def add(): #1. dosomething1 #2. io操作 # 1. dosomething3 global lock global total for i in range(1000000): lock.acquire() total += 1 lock.release()def desc(): global total global lock for i in range(1000000): lock.acquire() total -= 1 lock.release()import threadingthread1 = threading.Thread(target=add)thread2 = threading.Thread(target=desc)thread1.start()thread2.start()thread1.join()thread2.join()print(total)#1. 用锁会影响性能#2. 锁会引起死锁 Rlock lock.acquire()在同一个线程内不能连续出现，否则会出现死锁,即： 12345678910111213141516def add(): #1. dosomething1 #2. io操作 # 1. dosomething3 global lock global total for i in range(1000000): lock.acquire() do_someing() total += 1 lock.release()def do_someing() lock.acquire() total += 2 lock.release() 此种问题可用Rlock解决，注意，有多少lock.acquire()就要有多少lock.release() 12345678910111213141516from threading import RLocktotal = 0lock = RLock()def add(): #1. dosomething1 #2. io操作 # 1. dosomething3 global lock global total for i in range(1000000): lock.acquire() lock.acquire() total += 1 lock.release() lock.release() condition是条件变量， 用于复杂的线程间同步 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#通过condition完成协同读诗class XiaoAi(threading.Thread): def __init__(self, cond): super().__init__(name=\"小爱\") self.cond = cond def run(self): with self.cond: self.cond.wait() print(\"&#123;&#125; : 在 \".format(self.name)) self.cond.notify() self.cond.wait() print(\"&#123;&#125; : 好啊 \".format(self.name)) self.cond.notify() self.cond.wait() print(\"&#123;&#125; : 君住长江尾 \".format(self.name)) self.cond.notify()class TianMao(threading.Thread): def __init__(self, cond): super().__init__(name=\"天猫精灵\") self.cond = cond def run(self): with self.cond: print(\"&#123;&#125; : 小爱同学 \".format(self.name)) self.cond.notify() self.cond.wait() print(\"&#123;&#125; : 我们来对古诗吧 \".format(self.name)) self.cond.notify() self.cond.wait() print(\"&#123;&#125; : 我住长江头 \".format(self.name)) self.cond.notify() self.cond.wait()if __name__ == \"__main__\": from concurrent import futures cond = threading.Condition() xiaoai = XiaoAi(cond) tianmao = TianMao(cond) #启动顺序很重要 #在调用with cond之后才能调用wait或者notify方法 #condition有两层锁， 一把底层锁会在线程调用了wait方法的时候释放， 上面的锁会在每次调用wait的时候分配一把并放入到cond的等待队列中，等到notify方法的唤醒 xiaoai.start() tianmao.start() semaphoresemaphore是利用condition实现用于控制进入数量的锁 123456789101112131415161718192021222324252627282930313233343536#Semaphore 是用于控制进入数量的锁#文件， 读、写， 写一般只是用于一个线程写，读可以允许有多个#做爬虫import threadingimport timeclass HtmlSpider(threading.Thread): def __init__(self, url, sem): super().__init__() self.url = url self.sem = sem def run(self): time.sleep(2) print(\"got html text success\") self.sem.release() # 任务结束，释放锁class UrlProducer(threading.Thread): def __init__(self, sem): super().__init__() self.sem = sem def run(self): for i in range(20): self.sem.acquire() # 上锁，当数量大于3的时候阻塞 html_thread = HtmlSpider(\"https://baidu.com/&#123;&#125;\".format(i), self.sem) html_thread.start()if __name__ == \"__main__\": sem = threading.Semaphore(3) # 实例化Semaphore，限制同时最大数量为3 url_producer = UrlProducer(sem) url_producer.start() ThreadPoolExecutor线程池1234567891011121314151617181920212223242526272829303132333435363738394041424344454647from concurrent.futures import ThreadPoolExecutor, as_completed, wait, FIRST_COMPLETEDfrom concurrent.futures import Future# future未来对象，或者叫task的返回容器#线程池， 为什么要线程池#主线程中可以获取某一个线程的状态或者某一个任务的状态，以及返回值#当一个线程完成的时候我们主线程能立即知道#futures可以让多线程和多进程编码接口一致import timedef get_html(times): time.sleep(times) print(\"get page &#123;&#125; success\".format(times)) return timesexecutor = ThreadPoolExecutor(max_workers=2)#通过submit函数提交执行的函数到线程池中, submit 是立即返回task1 = executor.submit(get_html, (3))task2 = executor.submit(get_html, (2))# task1和task2就是future对象# done方法用于判定某个任务是否完成print(task1.done())print(task2.cancel()) # 取消某个还没运行的任务time.sleep(3)print(task1.done())# result方法可以获取task的执行结果print(task1.result())# 要获取已经成功的task的返回# 方法一，返回是按照任务成功的先后urls = [3,2,4]all_task = [executor.submit(get_html, (url)) for url in urls]for future in as_completed(all_task): data = future.result() print(\"get &#123;&#125; page\".format(data))# 方法二， 返回是按照urls里的顺序#通过executor的map获取已经完成的task的值for data in executor.map(get_html, urls): print(\"get &#123;&#125; page\".format(data)) # wait函数是等待一定条件（默认是所有任务执行完）满足后再继续执行主线程# return_when=FIRST_COMPLETED 参数是完成第一个任务后就继续执行主线程wait(all_task, return_when=FIRST_COMPLETED)print(\"main\") multiprocessing 多进程编程1234567891011121314151617181920212223242526272829303132333435import multiprocessingimport timedef get_html(n): time.sleep(n) print(\"sub_progress success\") return nif __name__ == \"__main__\": progress = multiprocessing.Process(target=get_html, args=(2,)) print(progress.pid) progress.start() print(progress.pid) progress.join() print(\"main progress end\") # 使用线程池 pool = multiprocessing.Pool(multiprocessing.cpu_count()) # 进程开启数量为cpu核心数 result = pool.apply_async(get_html, args=(3,)) # 等待所有任务完成 pool.close() pool.join() # join()前必须先close()否则会报错 print(result.get()) # imap 运行结果顺序为添加参数的顺序，即1,5,3 for result in pool.imap(get_html, [1,5,3]): print(\"&#123;&#125; sleep success\".format(result)) # imap_unordered 运行结果的顺序为执行时间的顺序，即1，3，5 for result in pool.imap_unordered(get_html, [1,5,3]): print(\"&#123;&#125; sleep success\".format(result)) 进程间通信 - Queue、Pipe，Managermultiprocessing.Queue 12345678910111213141516171819import timefrom multiprocessing import Process, Queue, Pooldef producer(queue): queue.put(\"a\") time.sleep(2)def consumer(queue): time.sleep(2) data = queue.get() print(data)if __name__ == \"__main__\": queue = Queue(10) my_producer = Process(target=producer, args=(queue,)) my_consumer = Process(target=consumer, args=(queue,)) my_producer.start() my_consumer.start() my_producer.join() my_consumer.join() Manager().Queue 12345678910111213141516171819202122from multiprocessing import Process, Manage, Pool# multiprocessing中的queue不能用于pool进程池# pool中的进程间通信需要使用manager中的queuedef producer(queue): queue.put(\"a\") time.sleep(2)def consumer(queue): time.sleep(2) data = queue.get() print(data)if __name__ == \"__main__\": queue = Manager().Queue(10) pool = Pool(2) pool.apply_async(producer, args=(queue,)) pool.apply_async(consumer, args=(queue,)) pool.close() pool.join() multiprocessing.Pipe 1234567891011121314151617181920from multiprocessing import Process, Pool, Pipe#通过pipe实现进程间通信#pipe的性能高于queuedef producer(pipe): pipe.send(\"bobby\")def consumer(pipe): print(pipe.recv())if __name__ == \"__main__\": recevie_pipe, send_pipe = Pipe() #pipe只能适用于两个进程 my_producer= Process(target=producer, args=(send_pipe, )) my_consumer = Process(target=consumer, args=(recevie_pipe,)) my_producer.start() my_consumer.start() my_producer.join() my_consumer.join() Manager().dict() 123456789101112131415161718from multiprocessing import Process, Managedef add_data(p_dict, key, value): p_dict[key] = valueif __name__ == \"__main__\": progress_dict = Manager().dict() from queue import PriorityQueue first_progress = Process(target=add_data, args=(progress_dict, \"bobby1\", 22)) second_progress = Process(target=add_data, args=(progress_dict, \"bobby2\", 23)) first_progress.start() second_progress.start() first_progress.join() second_progress.join() print(progress_dict) 第十二章 协程和异步IO并发、并行、同步、异步、阻塞、非阻塞并发：是指一个时间段内，有几个程序在同一个CPU上运行，但是任意时刻只有一个程序在CPU上运行。 并行：是指任意时刻点上，有多个程序同时运行在多个CPU上。 同步：是指代码调用IO操作时，必须等待IO操作完成才返回的调用方式。 异步：是指代码调用IO操作时，不必等IO操作完成就返回的调用方式。 阻塞：是指调用函数时候当前线程被挂起。 非阻塞：是指调用函数时候当前线程不会被挂起，而是立即返回。 I/O多路复用Unix下五种I/O模型： 阻塞式I/O、非阻塞式I/O、I/O复用、信号驱动式I/O，异步I/O(POSIX的aio_系列函数) 阻塞式I/O优于非阻塞式I/O的情况： 非阻塞式I/O不一定就好于阻塞式I/O，例如client.connect((host, 80))是阻塞式I/O，在此之后如果是执行client.send()，因为连接成功后才可以send，所以如果用client.setblocking(False)把它设置成非阻塞式I/O，那么在send之前就要不停的询问连接是否建立好， 需要while循环不停的去检查状态，否则如果没建立好连接就send，就可能会报错，阻塞式I/O不消耗CPU，而此时用while循环反而消耗CPU。 非阻塞式I/O优于阻塞式I/O的情况： 如果client.connect((host, 80))之后不是执行client.send()操作，而是做计算任务或者再次发起其他的连接请求，那么设置成非阻塞I/O，立刻执行下面的操作就不会报错，从而是提升了效率。 select是操作系统提供的函数，加入现在有100scoket连接，调用select函数，可以得到哪些socket连接完成，然后接收数据。 epoll并不代表一定比select好 在并发高的情况下，连接活跃度不是很高， epoll比select 并发性不高，同时连接很活跃， select比epoll好 select+回调+事件循环获取html过程： 1、把socket文件描述符、事件、回调函数注册进selector 2、使用loop()事件循环不停的请求socket的状态并调用对应的回调函数(select本身并不会在socket状态变化后调用回调函数，而是需要程序员写一个loop()事件循环的函数，不停请求socket状态，请求到某个socket状态完成，调用对应的回调函数) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#通过非阻塞io实现http请求# select + 回调 + 事件循环# 并发性高# 使用单线程import socketfrom urllib.parse import urlparsefrom selectors import DefaultSelector, EVENT_READ, EVENT_WRITEselector = DefaultSelector()#使用select完成http请求urls = []stop = Falseclass Fetcher: def connected(self, key): selector.unregister(key.fd) # 连接建立好之后要取消注册 self.client.send(\"GET &#123;&#125; HTTP/1.1\\r\\nHost:&#123;&#125;\\r\\nConnection:close\\r\\n\\r\\n\".format(self.path, self.host).encode(\"utf8\")) # 此处是监听是否可读 selector.register(self.client.fileno(), EVENT_READ, self.readable) def readable(self, key): d = self.client.recv(1024) if d: self.data += d else: selector.unregister(key.fd) data = self.data.decode(\"utf8\") html_data = data.split(\"\\r\\n\\r\\n\")[1] print(html_data) self.client.close() urls.remove(self.spider_url) if not urls: global stop stop = True def get_url(self, url): self.spider_url = url url = urlparse(url) self.host = url.netloc self.path = url.path self.data = b\"\" if self.path == \"\": self.path = \"/\" # 建立socket连接 self.client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) self.client.setblocking(False) try: self.client.connect((self.host, 80)) # 阻塞不会消耗cpu except BlockingIOError as e: pass # 注册，self.client.fileno()是socket的文件描述符，注册的是文件描述符 # 此处是监听是否可写 selector.register(self.client.fileno(), EVENT_WRITE, self.connected)def loop(): #事件循环，不停的请求socket的状态并调用对应的回调函数 #1. select本身是不支持register模式 #2. socket状态变化以后的回调是由程序员完成的 while not stop: ready = selector.select() for key, mask in ready: call_back = key.data call_back(key) #回调+事件循环+select(poll\\epoll)if __name__ == \"__main__\": fetcher = Fetcher() import time start_time = time.time() for url in range(20): url = \"http://shop.projectsedu.com/goods/&#123;&#125;/\".format(url) urls.append(url) fetcher = Fetcher() fetcher.get_url(url) loop() print(time.time()-start_time) 可读性差 共享状态管理困难 异常处理困难 生成器 传统函数调用 过程 A-&gt;B-&gt;C 我们需要一个可以暂停的函数，并且可以在适当的时候恢复该函数的继续执行 出现了协程 -&gt; 说法1：有多个入口的函数，说法2： 可以暂停的函数， 可以暂停的函数(可以向暂停的地方传入值) 生成器的方法： next(gen) gen.send() 1234567891011121314def gen_func(): # 1. 可以产出值， 2. 可以接收值(调用方传递进来的值) html = yield \"http://projectsedu.com\" print(html) return \"bobby\" if __name__ == \"__main__\": gen = gen_func() # 在调用send发送非none值之前，我们必须启动一次生成器， 方式有两种1. gen.send(None), 2. next(gen) url = gen.send(None) # download url html = \"bobby\" print(gen.send(html)) #send方法可以传递值进入生成器内部，同时还可以重启生成器执行到下一个yield位置 print(gen.send(html)) gen.close() 关闭生成器(如果在yield处捕获异常，就会在close()处抛出异常) gen.throw() 向生成器内传入异常 12345678910111213def gen_func(): try: yield \"http://projectsedu.com\" except Exception as e: pass yield 2 yield 3 return \"bobby\"if __name__ == \"__main__\": gen = gen_func() print(next(gen)) gen.throw(Exception, \"download error\") yield fromyield from的一个例子 123456789101112131415161718192021222324252627282930313233343536final_result = &#123;&#125;def sales_sum(pro_name): total = 0 nums = [] while True: x = yield print(pro_name+\"销量: \", x) if not x: break total += x nums.append(x) return total, numsdef middle(key): while True: final_result[key] = yield from sales_sum(key) print(key+\"销量统计完成！！.\")def main(): data_sets = &#123; \"bobby牌面膜\": [1200, 1500, 3000], \"bobby牌手机\": [28,55,98,108 ], \"bobby牌大衣\": [280,560,778,70], &#125; for key, data_set in data_sets.items(): print(\"start key:\", key) m = middle(key) m.send(None) # 预激middle协程 for value in data_set: m.send(value) # 给协程传递每一组的值 m.send(None) print(\"final_result:\", final_result)if __name__ == '__main__': main() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586# yield from的源码和解释#pep380#1. RESULT = yield from EXPR可以简化成下面这样#一些说明\"\"\"_i：子生成器，同时也是一个迭代器_y：子生成器生产的值_r：yield from 表达式最终的值_s：调用方通过send()发送的值_e：异常对象\"\"\"_i = iter(EXPR) # EXPR是一个可迭代对象，_i其实是子生成器；try: _y = next(_i) # 预激子生成器，把产出的第一个值存在_y中；except StopIteration as _e: _r = _e.value # 如果抛出了`StopIteration`异常，那么就将异常对象的`value`属性保存到_r，这是最简单的情况的返回值；else: while 1: # 尝试执行这个循环，委托生成器会阻塞； _s = yield _y # 生产子生成器的值，等待调用方`send()`值，发送过来的值将保存在_s中； try: _y = _i.send(_s) # 转发_s，并且尝试向下执行； except StopIteration as _e: _r = _e.value # 如果子生成器抛出异常，那么就获取异常对象的`value`属性存到_r，退出循环，恢复委托生成器的运行； breakRESULT = _r # _r就是整个yield from表达式返回的值。\"\"\"1. 子生成器可能只是一个迭代器，并不是一个作为协程的生成器，所以它不支持.throw()和.close()方法；2. 如果子生成器支持.throw()和.close()方法，但是在子生成器内部，这两个方法都会抛出异常；3. 调用方让子生成器自己抛出异常4. 当调用方使用next()或者.send(None)时，都要在子生成器上调用next()函数，当调用方使用.send()发送非 None 值时，才调用子生成器的.send()方法；\"\"\"_i = iter(EXPR)try: _y = next(_i)except StopIteration as _e: _r = _e.valueelse: while 1: try: _s = yield _y except GeneratorExit as _e: try: _m = _i.close except AttributeError: pass else: _m() raise _e except BaseException as _e: _x = sys.exc_info() try: _m = _i.throw except AttributeError: raise _e else: try: _y = _m(*_x) except StopIteration as _e: _r = _e.value break else: try: if _s is None: _y = next(_i) else: _y = _i.send(_s) except StopIteration as _e: _r = _e.value breakRESULT = _r\"\"\"看完代码，我们总结一下关键点：1. 子生成器生产的值，都是直接传给调用方的；调用方通过.send()发送的值都是直接传递给子生成器的；如果发送的是 None，会调用子生成器的__next__()方法，如果不是 None，会调用子生成器的.send()方法；2. 子生成器退出的时候，最后的return EXPR，会触发一个StopIteration(EXPR)异常；3. yield from表达式的值，是子生成器终止时，传递给StopIteration异常的第一个参数；4. 如果调用的时候出现StopIteration异常，委托生成器会恢复运行，同时其他的异常会向上 \"冒泡\"；5. 传入委托生成器的异常里，除了GeneratorExit之外，其他的所有异常全部传递给子生成器的.throw()方法；如果调用.throw()的时候出现了StopIteration异常，那么就恢复委托生成器的运行，其他的异常全部向上 \"冒泡\"；6. 如果在委托生成器上调用.close()或传入GeneratorExit异常，会调用子生成器的.close()方法，没有的话就不调用。如果在调用.close()的时候抛出了异常，那么就向上 \"冒泡\"，否则的话委托生成器会抛出GeneratorExit异常。\"\"\" chain函数 它接受一个可迭代对象列表作为输入，并返回一个迭代器，有效的屏蔽掉在多个容器中迭代细节。 123456789101112131415from itertools import chaina = [1, 2, 3, 4]b = ['x', 'y', 'z']for x in chain(a, b): print(x) &gt;&gt;&gt;1234xyz&gt;&gt;&gt; 偏函数partial partial函数的作用就是：将所作用的函数作为partial()函数的第一个参数，原函数的各个参数依次作为partial()函数的后续参数，原函数有关键字参数的一定要带上关键字，没有的话，按原有参数顺序进行补充。 偏函数的第二个部分(可变参数)，按原有函数的参数顺序进行补充，参数将作用在原函数上，最后偏函数返回一个新函数（类似于，装饰器decorator，对于函数进行二次包装，产生特殊效果；但又不同于装饰器，偏函数产生了一个新函数，而装饰器，可改变被装饰函数的函数入口地址也可以不影响原函数） 123456789101112def add(a,b,c=2): print(\"a is:%s b is %s c is %s\"%(a,b,c)) return a+b+cadd_with_a_b=partial(add,2,3)print(add_with_a_b())# it's 7add_with_a=partial(add,9)print(add_with_a(10))# it's 21#################a is:2 b is 3 c is 27a is:9 b is 10 c is 221 第十三章 asyncio并发编程事件循环使用asyncio 12345678910111213141516171819#事件循环+回调（驱动生成器）+epoll(IO多路复用)#asyncio是python用于解决异步io编程的一整套解决方案#tornado、gevent、twisted（scrapy， django channels）#torando(实现web服务器)， django+flask(uwsgi, gunicorn+nginx)#tornado可以直接部署， nginx+tornadoimport asyncioimport timeasync def get_html(url): print(\"start get url\") await asyncio.sleep(2) print(\"end get url\")if __name__ == \"__main__\": start_time = time.time() loop = asyncio.get_event_loop() tasks = [get_html(\"http://www.imooc.com\") for i in range(10)] loop.run_until_complete(asyncio.wait(tasks)) print(time.time()-start_time) 获取协程的返回值 1234567891011121314151617181920import asyncioimport timefrom functools import partialasync def get_html(url): print(\"start get url\") await asyncio.sleep(2) return \"bobby\"def callback(url, future): print(url) print(\"send email to bobby\")if __name__ == \"__main__\": start_time = time.time() loop = asyncio.get_event_loop() # get_future = asyncio.ensure_future(get_html(\"http://www.imooc.com\")) task = loop.create_task(get_html(\"http://www.imooc.com\")) task.add_done_callback(partial(callback, \"http://www.imooc.com\")) loop.run_until_complete(task) print(task.result()) 注： 1、callback是一个回调函数，作用是做完耗时操作后想做某一件事，例如发送邮件，可以用这种方法进行操作，必须接受一个future对象作为参数，加入task.add_done_callback后默认会添加future对象 2、 get_future = asyncio.ensure_future(get_html(“http://www.imooc.com&quot;)) loop.run_until_complete(get_future) 与 task = loop.create_task(get_html(“http://www.imooc.com&quot;)) loop.run_until_complete(task) 作用相同，task是get_future的一个子类 wait 和 gather asyncio.wait和asyncio.gather是等待一定条件（默认是所有任务执行完）满足后再继续执行下面的步骤 添加参数，也可以修改成第一个任务后就继续执行主线程 12345678910111213141516171819202122232425import asyncioimport timeasync def get_html(url): print(\"start get url\") await asyncio.sleep(2) print(\"end get url\")if __name__ == \"__main__\": start_time = time.time() loop = asyncio.get_event_loop() tasks = [get_html(\"http://www.imooc.com\") for i in range(10)] # loop.run_until_complete(asyncio.wait(tasks)) # loop.run_until_complete(asyncio.gather(*tasks)) # print(time.time()-start_time) #gather和wait的区别 #gather更加high-level # gather可以进行分组 group1 = [get_html(\"http://projectsedu.com\") for i in range(2)] group2 = [get_html(\"http://www.imooc.com\") for i in range(2)] group1 = asyncio.gather(*group1) group2 = asyncio.gather(*group2) group2.cancel() # 对未执行的分组进行取消 loop.run_until_complete(asyncio.gather(group1, group2)) print(time.time() - start_time)","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"IO","slug":"IO","permalink":"http://yoursite.com/tags/IO/"}],"keywords":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}]},{"title":"numpy和pandas","slug":"python/numpy和pandas","date":"2020-05-16T01:05:57.000Z","updated":"2020-05-16T02:09:17.035Z","comments":true,"path":"2020/05/16/python/numpy和pandas/","link":"","permalink":"http://yoursite.com/2020/05/16/python/numpy%E5%92%8Cpandas/","excerpt":"","text":"numpy创建数组12345678a = np.array([1,2,3,4,5])np.arange(12).reshape(3, 4)# 查看数组的类型type(a)# 查看数据的类型a.dtype 指定创建数组的数据类型1234a = np.array([1,0,1,0], dtype=np.bool) # 或者使用dtype='?'# 修改数组的数据类型a.astype(\"i1\") # 或者使用a.astype(np.int8) 修改浮点型的小数位数1np.round(b, 2) # b是浮点型数组 数组的形状123456789101112# 查看数组的形状,得到的结果是一个元组a.shape# 获取数组的行数a.shape[0]# 获取数组的列数a.shape[1]# 修改数组的形状b = a.reshape(2, 6)# 把数组转化为一维数组a.flatten() 数组和数组的计算123# 广播机制a + 1a * 3 如果两个数组的后缘维度（即从末尾开始算起的维度）的轴长度相符或其中一方的长度为1，则认为它们是广播兼容的。广播会在缺失和（或）长度为1的维度上进行。 可以把维度指的是shape所对应的数字。 也就是说两个数组shape得到的元组的后2位要相同，或者后2位中一个相同，另外一个数字有一个数组为1 numpy读取数据123np.loadtxt(fname,dtype=np.float,delimiter=None,skiprows=0,usecols=None,unpack=False)# 例如：np.loadtxt(US_video_data_numbers_path, delimiter=\",\", dtype=int,unpack=1) 参数 解释 frame 文件、字符串或产生器，可以是.gz或bz2压缩文件 dtype 数据类型，可选，csv的字符串以什么数据类型读入数组中，默认np.float delimiter 分割字符串，默认是任何空格，改为逗号 skiprows 跳过前X行，一般跳过第一行表头 usecols 读取指定的列，索引，元组类型 unpack 如果True，读入属性将分别写入不同数组变量，False读入数据只写入一个数组变量，默认False。相当于转置的效果 numpy中的转置转置是一种变换，对于numpy中的数组来说，就是在对角线方向交换数据，目的也是为了更方便的去处理数据。 1234# 转置的3种方法t.transpose()t.swapaxes(1,0)t.T numpy的索引和切片123456789a[1] # 取第2行a[1:3] # 取第2到第3行a[:, 2] # 取第3列a[:, 2:4] # 取第3到第4列a[[1,3], :] # 分别取第2行和第3行a[:[2,4]] # 分别取第3列和第4列a[[1:3],[2,4]] # 取第2行第3行和第3列第4列的交集a[:,2:8:2] # 取第3列到第8列，步长为2a[:,2:4] = 0 # 把第3列到第4列的值设置为0 numpy中布尔索引12345678910111213141516t = np.arange(24).reshape(4,6)print(t &lt; 10)&gt;&gt;&gt;array([[ True, True, True, True, True, True], [ True, True, True, True, False, False], [False, False, False, False, False, False], [False, False, False, False, False, False]])# 以上是t&lt;10的输出结果t[t&lt;10]=0print(t)&gt;&gt;&gt;[[ 0 0 0 0 0 0] [ 0 0 0 0 10 11] [12 13 14 15 16 17] [18 19 20 21 22 23]] numpy中的三元运算符把t中小于10的数字替换为0，把大于10的替换为10 1234567t = np.where(t&lt;10,0,10)print(t)&gt;&gt;&gt;[[ 0 0 0 0 0 0] [ 0 0 0 0 10 10] [10 10 10 10 10 10] [10 10 10 10 10 10]] numpy中的clip（裁剪）把t中小于10的数字替换为10，大于20的数字替换为20，其他数字不变 1234567t = t.clip(10, 20)print(t)&gt;&gt;&gt;[[10 10 10 10 10 10] [10 10 10 10 10 11] [12 13 14 15 16 17] [18 19 20 20 20 20]] numpy中的nan和infnan(NAN,Nan):not a number表示不是一个数字 什么时候会出现numpy中的nan： 当我们读取本地的文件为float的时候，如果有缺失，就会出现nan 当做了一个不合适的计算的时候（比如无穷大（inf）减去无穷大） inf(-inf,inf):infinity，inf表示正无穷，-inf表示负无穷 #####什么时候会出现inf(-inf,inf): 比如一个数字除以0，（python中直接回报错，numpy中是一个inf或者-inf） #####inf和nan的type类型都是float #####nan中的注意点： 两个nan是不相等的，即np.nan != np.nan 可以利用以上的特性，判断数组中nan的个数 np.count_nonzero(t != t) 如果判断一个数字是否为nan呢？通过np.isnan(a)来判断，返回bool类型，比较把nan替换为0 t[np.isnan(t)] = 0 nan和任何值计算都为nan numpy中常用统计函数 求和：t.sum(axis=None) 均值：t.mean(a,axis=None) 受离群点的影响较大 中值：np.median(t,axis=None) 最大值：t.max(axis=None) 最小值：t.min(axis=None) 极值：np.ptp(t,axis=None) 即最大值和最小值只差 标准差： t.std(axis=None) 默认返回多维数组的全部的统计结果，如果指定axis则返回一个当前轴上的结果 标准差：是一组数据平均值分散程度的一种度量。一个较大的标准差，代表大部分数值和其平均值之间差异较大；一个较小的标准差，代表这些数值较接近平均值反映出数据的波动稳定情况，越大表示波动越大，越不稳定。 ndarry缺失值填充均值1234567891011121314151617t = np.array([[ 0., 1., 2., 3., 4., 5.], [ 6., 7., np.nan, 9., 10., 11.], [ 12., 13., 14., np.nan, 16., 17.], [ 18., 19., 20., 21., 22., 23.]])def fill_nan_by_column_mean(t): for i in range(t.shape[1]): nan_num = np.count_nonzero(t[:, i][t[:, i] != t[:, i]]) # 计算非nan的个数 if nan_num &gt; 0: # 存在的nan值 now_col = t[:, i] now_col_not_nan = now_col[np.isnan(now_col) == False].sum() # 求和 now_col_mean = now_col_not_nan / (t.shape[0] - nan_num) # 和/个数 now_col[np.isnan(now_col)] = now_col_mean # 赋值给now_col t[:, i] = now_col # 赋值给t，即更新t的当前列 fill_nan_by_column_mean(t)print(t) 数组的拼接12np.vstack((t1,t2)) # 竖直拼接np.hstack((t1,t2)) # 水平拼接 数组的行列交换12t[[1,2],:] = t[[2,1],:] # 行交换t[:,[0,2]] = t[:,[2,0]] # 列交换 numpy更多好用的方法 获取最大值最小值的位置 np.argmax(t,axis=0) np.argmin(t,axis=1) 创建一个全0的数组：np.zeros((3,4)) 创建一个全1的数组：np.ones((3,4)) 创建一个对角线为1的正方形数组（方阵）：np,eye(3) 生成随机数 numpy的注意点copy和view a=b完全不复制，a和b相互影响 a=b[:]，视图的操作，一种切片，会创建新的对象a，但是a的数据完全由b保管，他们两个的数据变化是一致的。 a=b.copy()，复制，a和b互不影响。 pandasnumpy能够帮助我们处理数值，但是pandas除了处理数值之外（基于numpy），还能够帮助我们处理其他类型的数据 pandas之Series创建1234567891011121314151617181920212223242526272829303132333435363738# 方法一import stringt = pd.Series(np.arange(10), index=list(string.ascii_uppercase[:10]))# 方法二a = &#123;string.ascii_uppercase[i]:i for i in range(10)&#125;pd.Series(a)&gt;&gt;&gt;A 0B 1C 2D 3E 4F 5G 6H 7I 8J 9dtype: int64 # 重新指定索引pd.Series(a, index=list(string.ascii_uppercase[5:15]))&gt;&gt;&gt;F 5.0G 6.0H 7.0I 8.0J 9.0K NaNL NaNM NaNN NaNO NaNdtype: float64# 重新给其指定其他的索引之后，如果能够对应上，就取其值，如果不能，就为Nan# 为什么类型为float呢？numpy中nan为float，pandas会自动根据数据类更改series的dtype类型pandas修改dtype和numpy的方法一样 pandas之Series切片和索引切片：直接传入start end或者步长即可 索引：一个的时候直接传入序号或者index，多个的时候传入序号或者index的列表 12345678t = pd.Series(np.arange(10), index=list(\"ABCDEFGHIJ\")) t[2:10:2] # 切片 步长为2t[1] # 取索引t[[2,3,6]] # 取索引，索引分别为2，3，6t[t&gt;4] # 值大于4的所有数据t[\"F\"] # 索引为F的数据t[[\"A\", \"F\", \"g\"]] # 索引为A，F，g的数据，因为索引g没有，所以取出的值为NaN pandas之Series的索引和值Series对象本质上由两个数组构成，一个数组构成对象的键（index, 索引），一个数组构成对象的值（values），键-&gt;值 123456789101112131415t.index&gt;&gt;&gt;Index(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'], dtype='object')t.values&gt;&gt;&gt;array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])type(t.index)&gt;&gt;&gt;pandas.core.indexes.base.Indextype(t.values)&gt;&gt;&gt;numpy.ndarray ndarray的很多方法都可以运用于series类型，比如argmax，clip series具有where方法，但是结果和ndarray不同 Series的tolist()方法和unique()方法123456789df = pd.Series([1,2,1,3,2,1])df.tolist()&gt;&gt;&gt;[1, 2, 1, 3, 2, 1]df = pd.Series([1,2,1,3,2,1])df.unique()&gt;&gt;&gt;array([1, 2, 3]) pandas之读取外部数据12pd.read_csvpd.read_sql(sql_sentence, connection) pandas之DataFrame的创建12345678910111213141516# 方法一t = pd.DataFrame(np.arange(12).reshape(3,4),index=list(\"ABC\"),columns=list(\"WXYZ\"))# 方法二t_dict = &#123; \"name\":[\"zhangsan\", \"lisi\"], \"age\":[\"12\", \"20\"], &#125;pd.DataFrame(t_dict)# 方法三t_dict = [ &#123;\"name\": \"zhangsan\", \"age\": 12&#125;, &#123;\"name\": \"lisi\", \"age\": 20&#125;,]pd.DataFrame(t_dict) DataFrame的基础属性和整体情况查询12345678910111213# 基础属性df.shape # 行数 列数df.dtypes # 列数据类型df.ndim # 数据维度df.index # 行索引df.colums # 列索引df.values # 对象值，二维ndarray数组# 整体情况查询df.head(3) # 显示头部几行，默认5行de.tail(3) # 显示尾部几行，默认5行df.info() # 相关信息概览：行数，列数，列索引，列非空值个数，列类型，内存占用df.describe() # 快速综合统计结果：计数，均值，标准差，最大值，四分位数，最小值 对某一列进行排序12# 对Count_AnimalName列进行排序，ascending=False表示从大到小排序df.sort_values(by=\"Count_AnimalName\", ascending=False) DataFrame之取行或者列123456789df = pd.DataFrame(np.arange(56).reshape(7,8), index=list(\"ABCDEFG\"), columns=list(\"STUVWXYZ\"))# 取第X列df[\"X\"]# 取第X、Z列df[[\"X\", \"Z\"]]# 取第3到第6行df[2:6]# 取第3到第6行和第X列df[2:6][\"X\"] DataFrame之loc和iloc df.loc 通过标签索引行数据 Df.iloc 通过位置获取行数据 123456789101112131415# 取A行，W列交集的数据df.loc[\"A\", \"W\"]# 取A行和W、Z交集的数据df.loc[\"A\", [\"W\", \"Z\"]]# 取A、C行和W、Z交集的数据df.loc[[\"A\", \"c\"], [\"W\", \"Z\"]]# 取A行及A行之后所有行和W、Z的交集df.loc[\"A\": [\"W\", \"Z\"]]# 取A行到C行和W、Z的交集df.loc[\"A\":\"C\",[\"W\",\"Z\"]]# 取第2行到第3行和第3列、第4列的交集df.iloc[1:3, [2,3]]# 取第2行到第3行和第2列到第3列的交集df.iloc[1:3,1:3] 赋值更改数据的过程 12df.loc[\"A\", \"Y\"] = 100df.iloc[1:2,0:2] = 200 DataFrame之布尔索引1234567# 找到使用次数超过800的狗的名字df[df[\"Count_AnimalName\"]&gt;800]# 找到所有使用次数超过700并且名字的字符串的长度大于4的狗的名字df[(df[\"Row_Labels\"].str.len()&gt;4)&amp;(df[\"Count_AnimalName\"]&gt;700)]# &amp;符号表示：且# |符号表示：或 pandas之字符串方法 缺失数据的处理12345678910# 判断数据是否为NaNpd.isnull(df) # 是NaNpd.notnull(df) # 不是NaN# 处理方式1：删除NaN所在的行列t.dropna(axis=0,how='any',inplace=False)# 填充数据t.fillna(t.mean())t.fillna(t.median())t.fillna(0) 处理为0的数据：t[t==0]=np.nan 当然并不是每次为0的数据都需要处理 计算平均值等情况，nan是不参与计算的，但是0会 pandas常用统计方法12345678910111213# 评分的平均分rating_mean = df[\"Rating\"].mean()# 导演的人数temp_list = df[\"Actors\"].str.split(\",\").tolist()nums = set([i for j in temp_list for i in j])# 电影市场的最大最小值max_runtime = df[\"Runtime(Minutes)\"].max()max_runtime_index = df[\"Runtime(Minutes)\"].argmax()min_runtime = df[\"Runtime(Minutes)\"].min()min_runtime_index = df[\"Runtime(Minutes)\"].argmin()runtime_median = df[\"Runtime(Minutes)\"].median() 数据合并之join、mergejoin：默认情况下他是把行索引相同的数据合并到一起 merge:按照指定的列把数据按照一定的方式合并到一起 默认的合并方式inner：并集 outer：交集，NaN补全 left：左边为准，NaN补全 right：右边为准，NaN补全 分组和聚合1grouped = df.groupby(by=\"columns_name\") grouped是一个DataFrameGroupBy对象，是可迭代的。grouped中的每一个元素是一个元组元组里面是（索引(分组的值)，分组之后的DataFrame） 如果我们需要对国家和省份进行分组统计，应该怎么操作呢？ 1grouped = df.groupby(by=[df[\"Country\"],df[\"State/Province\"]]) 很多时候我们只希望对获取分组之后的某一部分数据，或者说我们只希望对某几列数据进行分组，这个时候我们应该怎么办呢？ 获取分组之后的某一部分数据： 1df.groupby(by=[\"Country\",\"State/Province\"])[\"Country\"].count() 对某几列数据进行分组： 1df[\"Country\"].groupby(by=[df[\"Country\"],df[\"State/Province\"]]).count() 观察结果，由于只选择了一列数据，所以结果是一个Series类型，如果我想返回一个DataFrame类型呢？ 12t1 = df[[\"Country\"]].groupby(by=[df[\"Country\"],df[\"State/Province\"]]).count()t2 = df.groupby(by=[\"Country\",\"State/Province\"])[[\"Country\"]].count() 以上的两条命令结果一样和之前的结果的区别在于当前返回的是一个DataFrame类型 索引和复合索引简单的索引操作： 获取index：df.index 指定index ：df.index = [‘x’,’y’] 重新设置index : df.reindex(list(“abcedf”)) 指定某一列作为index ：df.set_index(“Country”,drop=False) 返回index的唯一值：df.set_index(“Country”).index.unique() 12345678910111213141516171819202122232425262728a = pd.DataFrame(&#123;'a': range(7),'b': range(7, 0, -1),'c': ['one','one','one','two','two','two', 'two'],'d': list(\"hjklmno\")&#125;)a&gt;&gt;&gt; a b c d0 0 7 one h1 1 6 one j2 2 5 one k3 3 4 two l4 4 3 two m5 5 2 two n6 6 1 two ox = a.set_index([\"c\",\"d\"])[\"a\"]x&gt;&gt;&gt;c done h 0 j 1 k 2two l 3 m 4 n 5 o 6Name: a, dtype: int64 x[\"one\", \"h\"]&gt;&gt;&gt;0 x.swaplevel() 复合索引中交换索引 123456789101112x = x.swaplevel() x&gt;&gt;&gt;d c h one 0j one 1k one 2l two 3m two 4n two 5o two 6Name: a, dtype: int64 pandas中的时间序列时间序列的生成1pd.date_range(start=None, end=None, periods=None, freq='D') start和end以及freq配合能够生成start和end范围内以频率freq的一组时间索引start和periods以及freq配合能够生成从start开始的频率为freq的periods个时间索引 关于频率的更多缩写 在DataFrame中使用时间序列12index=pd.date_range(\"20170101\",periods=10)df = pd.DataFrame(np.random.rand(10),index=index) 可以使用pandas提供的方法把时间字符串转化为时间序列 1df[\"timeStamp\"] = pd.to_datetime(df[\"timeStamp\"],format=\"\")format参数大部分情况下可以不用写，但是对于pandas无法格式化的时间字符串，我们可以使用该参数，比如包含中文 pandas重采样重采样：指的是将时间序列从一个频率转化为另一个频率进行处理的过程，将高频率数据转化为低频率数据为降采样，低频率转化为高频率为升采样。 pandas提供了一个resample的方法来帮助我们实现频率转化 Periodlndex之前所学习的DatetimeIndex可以理解为时间戳那么现在我们要学习的PeriodIndex可以理解为时间段 1periods = pd.PeriodIndex(year=data[\"year\"],month=data[\"month\"],day=data[\"day\"],hour=data[\"hour\"],freq=\"H\")","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"},{"name":"numpy","slug":"python/numpy","permalink":"http://yoursite.com/categories/python/numpy/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"numpy","slug":"numpy","permalink":"http://yoursite.com/tags/numpy/"},{"name":"pandas","slug":"pandas","permalink":"http://yoursite.com/tags/pandas/"}],"keywords":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"},{"name":"numpy","slug":"python/numpy","permalink":"http://yoursite.com/categories/python/numpy/"}]},{"title":"常用反爬手段和解决办法","slug":"python/常用反爬手段和解决办法","date":"2020-05-16T01:05:57.000Z","updated":"2020-05-16T02:19:07.651Z","comments":true,"path":"2020/05/16/python/常用反爬手段和解决办法/","link":"","permalink":"http://yoursite.com/2020/05/16/python/%E5%B8%B8%E7%94%A8%E5%8F%8D%E7%88%AC%E6%89%8B%E6%AE%B5%E5%92%8C%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/","excerpt":"","text":"1、通过headers中的User-Agent字段来反爬解决办法：随机选择User-Agent 2、通过referer字段或者是其他字段来反爬解决办法：设置headers里的相应字段 3、通过cookie来反爬 方法1、session 实例化session（session具有的方法和requests一样） session发送请求post请求，对方服务器设置的cookie会保存在session session请求登录后能够访问的页面 方法2、cookie放在headers中 headers = {“Cookie”:”cookie字符串”} 方法3、cookie转化为字典放在请求方法中 requests.get(url,cookies={“name的值”:”values的值”}) 注意： 如果不需要登录时，需要携带cookie，也可以使用上述方法，而有时携带cookie反而容易被识别为爬虫 如果cookie过期时间比较久或者过期前就可以拿到想要的全部数据，一般才会使用方法2和方法3 如果需要登录，一般使用一个账户和密码多次请求是容易被识别为爬虫的，可以准备多个账号，通过一个程序获取账号对应的cookie，组成cookie池，爬虫程序使用这些cookie scrapy会在下一次请求时自动携带上一次的cookie，如果需要登录，也可以在请求时携带已登录的cookie，或者用scrapy.FormRequest或scrapy.FormRequest.from_response(form表单有action时)发送post请求 4、发送请求需要添加参数参数可能是发送其他url请求获取的，或者在页面响应中，此时需要我们用chrome的search file查找 5、通过js来反爬 通过js实现跳转来反爬 在请求目标网站的时候，我们看到的似乎就请求了一个网站，然而实际上在成功请求目标网站之前，中间可能有通过js实现的跳转，我们肉眼不可见，这个时候可以通过点击perserve log按钮实现观察页面跳转情况 在这些请求中，如果请求数量很多，一般来讲，只有那些response中带cookie字段的请求是有用的，意味着通过这个请求，对方服务器有设置cookie到本地 通过js生成了请求参数 对应的需要分析js，观察参数生成的实现过程 可以使用selenium模块解决 通过js实现了数据的加密 对应的需要分析js，观察加密的实现过程 可以使用selenium模块解决 6、通过验证码来反爬通过打码平台来识别验证码 7、基于用户行为反爬虫 还有一部分网站是通过检测用户行为，例如同一IP短时间内多次访问同一页面，或者同一账户短时间内多次进行相同操作。 大多数网站都是前一种情况，对于这种情况，使用IP代理就可以解决。可以专门写一个爬虫，爬取网上公开的代理ip，检测后全部保存起来。 对于第二种情况，可以在每次请求后随机间隔几秒再进行下一次请求。有些有逻辑漏洞的网站，可以通过请求几次，退出登录，重新登录，继续请求来绕过同一账号短时间内不能多次进行相同请求的限制。 8、通过自定义字体来反爬切换到手机版 9、通过css来反爬计算css的偏移","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"},{"name":"爬虫","slug":"python/爬虫","permalink":"http://yoursite.com/categories/python/%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"反爬","slug":"反爬","permalink":"http://yoursite.com/tags/%E5%8F%8D%E7%88%AC/"}],"keywords":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"},{"name":"爬虫","slug":"python/爬虫","permalink":"http://yoursite.com/categories/python/%E7%88%AC%E8%99%AB/"}]}]}